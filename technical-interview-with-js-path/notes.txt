1. Getting Started with Data Structures
2. JavaScript Linear Data Structures
    - Singly Linked Lists
    - Doubly Linked Lists
    - Queues
    - Stacks
3. Hash Maps
4. Algorithmic Concepts
    - Recursion
    - Asymptotic Notation
5. Nonlinear Data Structures
    - Trees
    - Binary Search and Search Trees
    - Heaps
6. Sorting Algorithms
    - Bubble Sort
    - Merge Sort
    - Quicksort 
7. Graph Data Structures
    - Graphs
    - Graph Traversals
    - Dijkstra's Algorithm
8. JavaScript Interview Prep and Algorithm Practice
    - Technical Interview Skills
    - JavaScript Algorithm Practice
        Sieve of Eratosthenes
        Capturing Rainwater
        Sorting with Custom Comparator Functions
        Introduction To Dynamic Programming in JavaScript
        The Knapsack Problem
-----------------------------------------------------------------------------------
1. Getting Started with Data Structures
    > Introduction to Data Structures
        you’ll use modern ES6 JavaScript and will build most of your code using class syntax.
        different iteration strategies to analyzing the algorithmic complexity of operations
        algorithms for efficient searching, sorting, and pathfinding.

        Why Data Structures?
            At the backbone of every program or piece of software are two entities: data and algorithms. Algorithms transform data into something a program can effectively use. Therefore, it is important to understand how to structure data so algorithms can maintain, utilize, and iterate through data quickly.
            Data structures are the way we are able to store and retrieve data. 
            DS provide us with a way to organize information in a digital space.

            How are data structures used?
                Data structures handle four main functions for us:
                - Inputting information     - is concerned with how the data is received
                    Will the new data be added to the beginning, end, or somewhere in the middle of the existing data? 
                    Does an existing point of data need to be updated or destroyed?
                - Processing information    - the way that data is manipulated in the data structure
                    How does existing data that has been stored need to change to accommodate new, updated, or removed data?
                - Maintaining information   - is focused on how the data is organized within the structure.
                    Which relationships need to be maintained between pieces of data? 
                    How much memory must the system reserve (allocate) to accommodate the data?
                - Retrieving information    - is devoted to finding and returning the data that is stored in the structure.
                    How can we access that information again? 
                    What steps does the data structure need to take to get the information back to us?
            
            Different types and use cases for data will be better suited to different manners of inputting, processing, storing, and retrieving. This is why we have several data structures to choose from… and the ability to create our own!
            Different data structures are better suited for different tasks. Choosing the wrong data structure can result in slow or unresponsive code (and mess up your program!), so it’s important to consider a few factors as you make your decision:
            - What is the intended purpose for the data? Do any data structures have built-in functionality that is ideally suited for this purpose? Do you want to search, sort, or iterate data in a way in which certain data structures would be better suited than others?
            - Do you want or need control over how memory is set aside to store your data? Data structures that use static memory allocation (e.g., stacks or arrays) will manage memory for you and assume a fixed amount of memory upon instantiation with a cap on how much data may be added. Data structures that utilize dynamic memory allocation (e.g., heaps or linked lists) allow you to allocate and reallocate memory within the life of the program. While memory allocation is not something that you’ll need to consider in languages like Python or Javascript (these languages will manage memory for you, regardless of which data structure you use), it is something to bear in mind when working in other languages like C.
            - How long will it take different data structures to accomplish various tasks relative to other data structures? Technically, two data structures may both be able to accomplish the same task for you, but one may be quite a bit faster. This consideration, known as runtime will be covered further in depth when you explore all the nifty tricks of asymptotic notation.
            As you’ve seen, data structures are the essential building blocks that we use to organize all of our digital information. Choosing the right data structure allows us to use the algorithms we want and keeps our code running smoothly. Understanding data structures and how to use them well can play a vital role in many situations including:
                - technical interviews in which you may be asked to evaluate and determine runtime for data structures given specific algorithms
                - day-to-day work for many software engineers who manipulate data stored in structures
                - data science work where data is stored and accessed through data structures
                - a whole lot more!
        
        Data Structure APIs
            Do you need to store data in an ordered way, or do you just need to be able to store it and retrieve it quickly? 
            What’s more important to your use case: how fast the data structure performs, or how much memory it takes up? 
            Different data structures all have advantages, disadvantages, and use cases, and that’s the whole reason that there are different data structures!

            Consider the Array in JavaScript. It’s a really great data structure for storing ordered data because you can retrieve elements by index number. If you want the first element of an array, all you need to do is fetch it with index 0: arrayName[0]. It also provides all sorts of helpful methods for manipulating elements, such as .push(), .pop(), .sort(), and more. However, if you want to find out if a particular element exists in an array, you may need to iterate through the entire array.
                const listOfNumbers = [];
                const storeNumber = num => listOfNumbers.push(num);
                const doYouHaveThisNumber = num => listOfNumbers.includes(num);
                // doYouHaveThisNumber() might start getting pretty slow, since Array.prototype.includes() iterates through the entire array until it finds the input value.
            
            Let’s try using another built-in data type in JavaScript, the Object. Since all we want to keep track of is whether we received a particular number, we can just store those numbers in an object, and set their values to true if we received them.
                const receivedNumbers = {};
                const storeNumber = num => receivedNumbers[num] = true;
                const doYouHaveThisNumber = num => receivedNumbers[num] === true;
                // retrieving a value from an object is much faster than iterating through an array, the overall result will be faster.
            
            In both cases, the public API of the code, meaning the parts of the code that we want the end-user to interact with, remained the same: we had two functions, storeNumber() and doYouHaveThisNumber(). The underlying implemenation, or the way the functionality was actually achieved, is what altered.

            What is an API?
                API is an acronym for application programming interface. An API allows end-users to access properties and methods of data structures easily and without needing to do the “behind the scenes” work.
                The API of arrays https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array
            
            Creating Your Own APIs
                An API is like a message to end-users. Some languages have classes that can have methods or fields that are either public (can be called from anywhere) or private (can only be called from within the class). Public methods are the ones that end-users of that class can call, and private methods are only used by the class itself. JavaScript doesn’t really support this concept, so properties that aren’t meant to be public are often preceded by an underscore _. Let’s look at an example where we want to build a data structure with a restricted API.
                A stack is a data structure that only allows data to be added (pushed) or removed (popped) from the “top” of the stack. It just so happens that we could use an array as a stack, since it already has a .push() and .pop() method! However, arrays also allow you to add elements to the beginning or randomly access elements by index.
                We’re not going to cover all the ins and outs of the stack data structure right now, but to demonstrate public API vs implementation, let’s build a quick custom Stack class:

                    class Stack {
                        constructor() {
                            this._array = [];   // In Stack, the array itself is stored as _array, so it’s a signal to other developers that to use the Stack as intended, they shouldn’t need to access it directly.
                        }

                        push(newValue) {
                            this._array.push(newValue);
                        }

                        pop() {
                            return this._array.pop();
                        }
                    }

                Now we’ve created a Stack data structure that limits direct interaction with the underlying data to .push() and .pop(). A developer could still access our underlying array to do other manipulation:
                    const stack = new Stack();
                    stack._array.unshift('value');
                but they would then be breaking the intended behavior of the Stack class. The whole point of a public API is that we offer functionality to other end-users. If somebody were using our Stack class in a program, we could totally change the underlying implementation, and as long as the end-user API remained the same, their program should continue to function.
                As you build your own classes and data structures, it’s important to keep in mind this distinction between implementation (what does this need internally to do its job) and the outside API (how should users of this actually interact with it?).
                
    > Nodes
        Nodes Introduction
            Nodes are the fundamental building blocks of many computer science data structures. 
            They form the basis for linked lists, stacks, queues, trees, and more.
            An individual node contains data and links to other nodes. Each data structure adds additional constraints or behavior to these features to create the desired structure.
            Example: Node (node_a) contains a piece of data (the number 5) and a link to another node (node_b).

            Nodes Detail
                The data contained within a node can be a variety of types, depending on the language you are using. In the previous example, it was an integer (the number 5), but it could be a string ("five"), decimal (5.1), an array ([5,3,4]) or nothing (null).
                The link or links within the node are sometimes referred to as pointers. This is because they “point” to another node.
                Typically, data structures implement nodes with one or more links. If these links are null, it denotes that you have reached the end of the particular node or link path you were previously following.

            Node Linking
                Often, due to the data structure, nodes may only be linked to from a single other node. This makes it very important to consider how you implement modifying or removing nodes from a data structure.
                If you inadvertently remove the single link to a node, that node’s data and any linked nodes could be “lost” to your application. When this happens to a node, it is called an orphaned node.
                Examine the nodes in the diagram. node_c is only linked to by node_b. If you would like to remove node_b but not node_c, you can’t simply delete the link from node_a to node_b.
                The most straightforward method to preserve node_c would be to change the link in node_a to point to node_c instead of node_b. However, some data structures may handle this in a different manner.

            Nodes Review
                Nodes:
                    - Contain data, which can be a variety of data types
                    - Contain links to other nodes. If a node has no links, or they are all null, you have reached the end of the path you were following.
                    - Can be orphaned if there are no existing links to them

            Nodes in JavaScript
                We will create a basic node that contains data and one link to another node. The node’s data will be specified when creating the node and immutable (can’t be updated). Remember that a node’s link to the next node is null when there are no nodes to traverse.
                Go ahead and take a look at the starter code in the editor. You will find the Node class defined. module.exports allows the Node class to be used outside this module. Make sure to always leave this line of code. We’ll need it when we use this class to implement more complex data structures.

                class Node {                    // classes are created using the class expression, and constructor is a method that will run when an instance of the class is first created.
                  constructor(data) {           // setting up the constructor for our Node class, we want the constructor to expect a data argument of any type to be passed in. 
                    this.data = data
                    this.next = null            // When the node is first created, it is an orphan node (a node with no links). Set the next node to null.
                  }
                }
                
                const firstNode = new Node(5);  // instantiate a Node with any value and set it to firstNode. Create a Node instance using the new operator and assign it to the variable firstNode.
                console.log(firstNode.data);    // print out the instance’s data property.
                console.log(firstNode.next);    // print out the instance’s next node property.
                module.exports = Node;          // allows the Node class to be used outside this module.

            Node Methods: Set Next Node
                Currently when a node is created, the next node is initially set to null, and we do not have a formal way to change it. However, we want to allow the next node to be updated so it can be traversed and used in more complex data structures. For this, we will use a setter to modify this.next node property.

                    class Node {
                        constructor(data) {
                            this.data = data;
                            this.next = null;
                        }
                        setNextNode(node){
                            this.next = node;
                        }
                    }
                    const firstNode = new Node('I am an instance of a Node!');
                    const secondNode = new Node('hi')
                    firstNode.setNextNode(secondNode)
                    console.log(firstNode)
                    console.log(secondNode)
                    module.exports = Node;
            
            Node Methods: Set Next Node Validation
                We arbitrarily set our next node to any argument that gets passed in. This can be problematic. Imagine if the next node accidentally gets set to a different data type, like a string. We run the risk of mistakenly confusing the string for a node, and we would have to build out special support to avoid traversing anything that is not a node.
                To prevent these unnecessary complications, let’s add in a check that only allows arguments that are instanceof nodes or null. We want to allow null values as an argument in the event that we want to break the link between a node and its next node.

                    class Node {
                        constructor(data) {
                            this.data = data;
                            this.next = null;
                        }
                        
                        setNextNode(node) {
                            if(node instanceof Node || node === null){
                                this.next = node;
                            } else {
                                throw new Error('Next node must be a member of the Node class.');
                            }
                        }
                    }
                    const firstNode = new Node('I am an instance of a Node!');
                    firstNode.setNextNode(5)    // Error: Next node must be a member of the Node class.
                    module.exports = Node;

            Node Methods: Get Next Node
                We could continue accessing the next node property directly, like how we have been doing so far. However, if we ever want it to be given in a special way, we would want to use a getter to handle the preprocessing.
                Let’s go ahead and create a simple .getNextNode() method that just returns the next node property.
                    
                    class Node {
                        ...
                        getNextNode() {
                            return this.next;
                        }
                    }
                    const firstNode = new Node('I am an instance of a Node!');
                    const secondNode = new Node('I am the next Node!');
                    firstNode.setNextNode(secondNode);
                    console.log(firstNode.getNextNode());

                Example:
                    class Node {
                        ...
                    }
                    const strawberryNode = new Node('Berry Tasty');
                    const vanillaNode = new Node('Vanilla');
                    const coconutNode = new Node('Coconuts for Coconut');

                    vanillaNode.setNextNode(strawberryNode);
                    strawberryNode.setNextNode(coconutNode);

                    let currentNode = vanillaNode;
                    while(currentNode) {
                        console.log(currentNode.data);
                        currentNode = currentNode.getNextNode();
                    }

2. JavaScript Linear Data Structures
    > Singly Linked Lists       a -> b -> c
        Linked Lists
            Linking together nodes using their next property creates a singly linked list. Singly linked lists are extremely versatile and useful, while also beautiful in their simplicity. Like nodes, these lists are used as foundations for future data structures and are an alternative to arrays when trying to store information in a linear way.
            Linked lists are one of the basic data structures used in computer science. They have many direct applications and serve as the foundation for more complex data structures.
            
            The list is comprised of a series of nodes as shown in the diagram. The head node is the node at the beginning of the list. Each node contains data and a link (or pointer) to the next node in the list. The list is terminated when a node’s link is null. This is called the tail node.
            Consider a one-way air travel itinerary. The trip could involve traveling through several airports (nodes) connected by air travel segments (links). In this example, the initial departure city is the head node and the final arrival city is the tail node.
            Since the nodes use links to denote the next node in the sequence, the nodes are not required to be sequentially located in memory. These links also allow for quick insertion and removal of nodes
            Common operations on a linked list may include:
                - adding nodes
                - removing nodes
                - finding a node
                - traversing (or travelling through) the linked list
            Linked lists typically contain unidirectional links (next node), but some implementations make use of bidirectional links (next and previous nodes).
        
            Linked List Example
                This linked list contains three nodes (node_a, node_b, and node_c).
                Each node in this particular list contains a string as its data. As the sequence is defined, the order is "cats", "dogs", and "birds".
                The list ends at node_c, since the link within that node is set to null.
            
            Linked Lists Adding and Removing Nodes
                Adding a new node
                    Adding a new node to the beginning of the list requires you to link your new node to the current head node. This way, you maintain your connection with the following nodes in the list.
                Removing a node
                    If you accidentally remove the single link to a node, that node’s data and any following nodes could be lost to your application, leaving you with orphaned nodes.
                    To properly maintain the list when removing a node from the middle of a linked list, you need to be sure to adjust the link on the previous node so that it points to the following node.
                    Depending on the language, nodes which are not referenced are removed automatically. “Removing” a node is equivalent to removing all references to the node.
            
            Linked List Review
                Linked Lists:
                    - Are comprised of nodes
                    - The nodes contain a link to the next node (and also the previous node for bidirectional linked lists)
                    - Can be unidirectional or bidirectional
                    - Are a basic data structure, and form the basis for many other data structures
                    - Have a single head node, which serves as the first node in the list
                    - Require some maintenance in order to add or remove nodes
                    - The methods we used are an example and depend on the exact use case and/or programming language being used

            Constructor and Adding to Head
                Let’s implement a linked list in JavaScript. As you might recall, a linked list is a sequential chain of nodes. Remember that a node contains two elements:
                    - data
                    - a link to the next node
                We are going to use a provided Node class:
                    // Node.js  file
                    class Node {
                        constructor(data) {
                            this.data = data;
                            this.next = null;
                        }
                        setNextNode(node) {
                            if (!(node instanceof Node)) {
                                throw new Error('Next node must be a member of the Node class');
                            }
                            this.next = node;
                        }
                        getNextNode() {
                            return this.next;
                        }
                    }
                    module.exports = Node;
                
                Depending on the end-use of the linked list, there are a variety of methods that we can define. 
                For our use, we want to be able to:
                    - add a new node to the beginning (head) of the list
                    - add a new node to the end (tail) of the list
                    - remove a node from the beginning (head) of the list
                    - print out the nodes in the list in order from head to tail

                    // LinkedList.js
                    const Node = require('./Node');
                    class LinkedList {
                        constructor() {
                            this.head = null;
                        }
                        addToHead(data) {
                            const newHead = new Node(data);
                            const currentHead = this.head;
                            this.head = newHead;
                            if (currentHead) {
                                this.head.setNextNode(currentHead);
                            }
                        }
                    }
                    module.exports = LinkedList;
            
            Adding to Tail
                Now that we can add to the head of the linked list, the next step is to be able to add to the tail. This will require a few more steps since we don’t have a tail property in our linked list data structure.
                To do this, we are going to start with a temporary tail variable that will be set equal to the list’s head. If there is no head, that means that the list is empty, and we will add the node to the head of the list. Otherwise, we will iterate through the list until we find the last node. Once we’ve found the current tail, we will add a pointer from that node to our new tail.
                
                    class LinkedList {
                        ...
                        addToTail(data){
                            let tail = this.head;
                            if(!tail){
                                this.head = new Node(data)
                            } else {
                                while(tail.getNextNode()){
                                    tail = tail.getNextNode()
                                }
                                tail.setNextNode(new Node(data))
                            }
                        }
                    }
            
            Removing the Head
                To do this, we are first going to check to see if the list has a head. If it doesn’t, there is nothing to return. If there is a head, we will remove it by setting the list’s head equal to the original head’s next node, and then return that original head.

                    class LinkedList {
                        ...
                        removeHead(){
                            const removedHead = this.head;
                            if(!removedHead){
                                return ;
                            }
                            this.head = removedHead.getNextNode()
                            return removedHead.data;
                        }
                    }
            
            Printing
                While it’s possible to just use console.log() on the list (try it!), we want to print it in a more understandable and readable way. console.log() will print the pointers of each node as well as the data, but we’re just going to print the data while maintaining the order of the list.
                To do this, we will create a String that holds the data from every node in the list. We’ll start at the list’s head and iterate through the list, adding to our String as we go.

                class LinkedList {
                    ...
                    printList(){
                        let currentNode = this.head
                        let output = '<head> '
                        while(currentNode !== null){
                            output += currentNode.data + ' ';
                            currentNode = currentNode.getNextNode();
                        }
                        output += '<tail>'
                        console.log(output);
                    }
                }
            
            Using the Linked List
                To create an instance of that class and create a linked list of the seasons:
                    //seasons.js
                    const LinkedList = require('./LinkedList');
                    const seasons = new LinkedList();

                    seasons.printList()
                    seasons.addToHead('summer')
                    seasons.addToHead('spring')
                    seasons.printList()

                    seasons.addToTail('fall')
                    seasons.addToTail('winter')
                    seasons.printList()

                    seasons.removeHead();
                    seasons.printList()

            Linked List Review
                We created and implemented a linked list class in JavaScript by:
                    - Using our Node class to hold the data and links between nodes
                    - Implementing a LinkedList class to handle external operations on the list, like adding and removing nodes
                    - Creating an instance of our list, and using our .printList() method to track the changes we made
            
    > Doubly Linked Lists   a <-> b <-> c
        While a singly linked list consists of nodes with links from the one node to the next, a doubly linked list also has a link to the node before it. These previous links, along with the added tail property, allow you to iterate backward through the list as easily as you could iterate forward through the singly linked list.

        Like a singly linked list, a doubly linked list is comprised of a series of nodes. Each node contains data and two links (or pointers) to the next and previous nodes in the list. The head node is the node at the beginning of the list, and the tail node is the node at the end of the list. The head node’s previous pointer is set to null and the tail node’s next pointer is set to null.
        Think of your daily commute on the subway as a real-world example of a doubly linked list. Your home is the head of the list, your place of work is the tail, and every stop in between is another node in the list. In the morning when you take the subway to get to work, you are traversing the list from the head to the tail, using the stop’s next pointer. While this can also be done using a singly linked list, a doubly linked list will also allow you to traverse back through the list easily, using the stop’s previous pointer. You will take the exact same route to get home, just in reverse.
        Common operations on a doubly linked list may include:
            - adding nodes to both ends of the list
            - removing nodes from both ends of the list
            - finding, and removing, a node from anywhere in the list
            - traversing (or traveling through) the list
        
        Adding to the Head
            When adding to the head of the doubly linked list, we first need to check if there is a current head to the list. If there isn’t, then the list is empty, and we can simply make our new node both the head and tail of the list and set both pointers to null. If the list is not empty, then we will:
            - Set the current head’s previous pointer to our new head
            - Set the new head’s next pointer to the current head
            - Set the new head’s previous pointer to null
        Adding to the Tail
            Similarly, there are two cases when adding a node to the tail of a doubly linked list. If the list is empty, then we make the new node the head and tail of the list and set the pointers to null. If the list is not empty, then we:
            - Set the current tail’s next pointer to the new tail
            - Set the new tail’s previous pointer to the current tail
            - Set the new tail’s next pointer to null
        
        Removing the Head
            Removing the head involves updating the pointer at the beginning of the list. We will set the previous pointer of the new head (the element directly after the current head) to null, and update the head property of the list. If the head was also the tail, the tail removal process will occur as well.

        Removing the Tail
            Similarly, removing the tail involves updating the pointer at the end of the list. We will set the next pointer of the new tail (the element directly before the tail) to null, and update the tail property of the list. If the tail was also the head, the head removal process will occur as well.

        Removing from the Middle of the List
            It is also possible to remove a node from the middle of the list. Since that node is neither the head nor the tail of the list, there are two pointers that must be updated:
            We must set the removed node’s preceding node’s next pointer to its following node
            We must set the removed node’s following node’s previous pointer to its preceding node
            There is no need to change the pointers of the removed node, as updating the pointers of its neighboring nodes will remove it from the list. If no nodes in the list are pointing to it, the node is orphaned.

        Doubly Linked Lists Review 
            Doubly Linked Lists:
            - Are comprised of nodes that contain links to the next and previous nodes
            - Are bidirectional, meaning it can be traversed in both directions
            - Have a pointer to a single head node, which serves as the first node in the list
            - Have a pointer to a single tail node, which serves as the last node in the list
            - Require the pointers at the head of the list to be updated after addition to or removal of the head
            - Require the pointers at the tail of the list to be updated after addition to or removed of the head
            - Require the pointers of the surrounding nodes to be updated after removal from the middle of the list
            Your browser history is another example of a doubly linked list. When you open your browser, the page that you land on is the head of your list. As you click on things and navigate to new pages, you are moving forward and adding to the tail of your list. If you ever want to go back to something you’ve already visited, you can use the “back” button to move backward through your list. 

        We will reuse the .printList() method from our LinkedList class, but the rest will either be edited or new.

            // Node.js
            class Node {
                constructor(data) {
                    this.data = data;
                    this.next = null;
                    this.previous = null;
                }
                setNextNode(node) {
                    if (node instanceof Node || node === null) {
                        this.next = node;
                    } else {
                        throw new Error('Next node must be a member of the Node class')
                    }
                }
                setPreviousNode(node) {
                    if (node instanceof Node || node === null) {
                        this.previous = node;
                    } else {
                        throw new Error('Next node must be a member of the Node class')
                    }
                }
                getNextNode() {
                    return this.next;
                }

                getPreviousNode() {
                    return this.previous;
                }
            }
            module.exports = Node;

            // DoublyLinkedList.js
            const Node = require('./Node');
            class DoublyLinkedList {
                constructor(){
                    this.head = null;
                    this.tail = null;
                }
                addToHead(data){
                    const newHead = new Node(data);
                    const currentHead = this.head;
                    if(currentHead){
                        currentHead.setPreviousNode(newHead)
                        newHead.setNextNode(currentHead)
                    }
                    this.head = newHead;
                    if(!this.tail){
                        this.tail = newHead;
                    }
                }
                addToTail(data){
                    const newTail = new Node(data);
                    const currentTail = this.tail;
                    if(currentTail){
                        currentTail.setNextNode(newTail);
                        newTail.setPreviousNode(currentTail)
                    }
                    this.tail = newTail;
                    if(!this.head){
                        this.head = newTail
                    }
                }
                removeHead(){
                    const removedHead = this.head;
                    if(!removedHead){
                        return ;
                    }
                    this.head = removedHead.getNextNode();
                    if(this.head){
                        this.head.setPreviousNode(null)
                    }
                    if(removedHead === this.tail){
                        this.removeTail()
                    }
                    return removedHead.data;
                }
                removeTail(){
                    const removedTail = this.tail;
                    if(!removedTail){
                        return ;
                    }
                    this.tail = removedTail.getPreviousNode()
                    if(this.tail){
                        this.tail.setNextNode(null) 
                    }
                    if(removedTail === this.head){
                        this.removeHead();
                    }
                    return removedTail.data;
                }
                removeByData(data) {
                    let nodeToRemove;
                    let currentNode = this.head;
                    while (currentNode !== null) {
                        if (currentNode.data === data) {
                            nodeToRemove = currentNode;
                            break;
                        }
                        currentNode = currentNode.getNextNode();
                    }
                    if (!nodeToRemove) {
                        return null;
                    }
                    
                    if(nodeToRemove === this.head){
                        this.removeHead();
                    } else if(nodeToRemove === this.tail) {
                        this.removeTail();
                    } else {
                        const nextNode = nodeToRemove.getNextNode()
                        const previousNode = nodeToRemove.getPreviousNode();
                        nextNode.setPreviousNode(previousNode)
                        previousNode.setNextNode(nextNode)
                    }
                    return nodeToRemove;
                }
                printList() {
                    let currentNode = this.head;
                    let output = '<head> ';
                    while (currentNode !== null) {
                        output += currentNode.data + ' ';
                        currentNode = currentNode.getNextNode();
                    }
                    output += '<tail>';
                    console.log(output);
                }
            }
            module.exports = DoublyLinkedList;

            // subway.js
            const DoublyLinkedList = require('./DoublyLinkedList.js');

            const subway = new DoublyLinkedList()
            subway.addToHead('TimesSquare')
            subway.addToHead('GrandCentral')
            subway.addToHead('CentralPark')
            subway.printList()
            
            subway.addToTail('PennStation')
            subway.addToTail('WallStreet')
            subway.addToTail('BrooklynBridge')
            subway.printList()
            
            subway.removeHead()
            subway.removeTail()
            subway.printList()
            
            subway.removeByData('TimesSquare')
            subway.printList()


    > Linked List Practice
        Swapping Elements in a Linked List
            // Since singly linked lists only have pointers from each node to its next node, swapping two nodes in the list isn’t as easy as doing so in an array (where you have access to the indices). You not only have to find the elements, but also reset the pointers around them to maintain the integrity of the list. This means keeping track of the two nodes to be swapped as well as the nodes preceding them.
            Given an input of a linked list, data1, and data2, the general steps for doing so is as follows:
                1. Iterate through the list looking for the node that matches data1 to be swapped (node1), keeping track of the node’s previous node as you iterate (node1Prev)
                    // Finding the Matching and Preceding Nodes
                    // Let’s look at what implementing steps 1 and 2 looks like. In order to swap the two nodes, we must first find them. We also need to keep track of the nodes that precede them so that we can properly reset their pointers. (We will use the Node classes .getNextNode() method in order to access the next node.)
                    // We will start by setting node1 equal to the head of the list, and then creating a while loop that runs while node1 isn’t null. Inside the loop, we will check if node1‘s data matches data1. If so, we break out of the loop as we have found the correct node. If there is no match, we update node1Prev to be node1 and move node1 to its next node
                    // At the end of this, we have found our matching node, and also saved its previous node, which we will use in the next step.

                        function swapNodes(list, data1, data2) {
                            let node1 = list.head;
                            let node2 = list.head;
                            let node1Prev = null;
                            let node2Prev = null;
                            
                            while (node1 !== null) {
                                if (node1.data === data1) {
                                    break;
                                }
                                node1Prev = node1;
                                node1 = node1.getNextNode();
                            }
                        }

                2. Repeat step 1 looking for the node that matches data2 (giving you node2 and node2Prev)
                3. If node1Prev is null, node1 was the head of the list, so set the list’s head to node2
                    // Updating the Preceding Nodes’ Pointers
                    // Our next step is to set node1Prev and node2Prev‘s next nodes, starting with node1Prev. We will start by checking if node1Prev is null. If it is, then the node1 is the head of the list, and so we will update the head to be node2. If node1Prev isn’t null, then we set its next node to node2:
                    // After this step, we have finished updating the pointers that point to our swapped nodes. The next step will be to update the pointers from them.

                        // Still inside the swapNodes() function
                        if (node1Prev === null) {
                            list.head = node2;
                        } else {
                            node1Prev.setNextNode(node2);
                        }

                4. Otherwise, set node1Prev‘s next node to node2
                5. If node2Prev is null, set the list’s head to node1
                6. Otherwise, set node2Prev‘s next node to node1
                7. Set node1‘s next node to node2‘s next node
                    // Updating the Nodes’ Next Pointers
                    // The last step is to update the pointers from node1 and node2. This is relatively simple, and mirrors a swapping function for an array in that we will use a temporary variable.

                        let temp = node1.getNextNode();
                        node1.setNextNode(node2.getNextNode());
                        node2.setNextNode(temp);

                8. Set node2‘s next node to node1‘s next node

                Edge Cases
                    We have completed the basic swap algorithm in JavaScript! However, we haven’t accounted for some base cases. 
                    
                    9. What if there is no matching node for one of the inputs? 
                    The current swapNodes() function will not run because we will try to access the next node of a node that is null. 
                    (Remember that our initial while loop only breaks if the matching node is found. Otherwise, it runs until the node is null.) 
                    Thankfully this has a quick fix. 
                    We can put in an if that checks if either node1 or node2 is null. 
                    If they are, we can print a statement that explains a match was not found, and return to end the method. 
                    We can put this right after the while loops that iterate through the list to find the matching nodes:
                        
                        // put this right after the while loops
                        if (node1 === null || node2 === null) {
                            console.log('Swap not possible - one or more element is not in the list')
                            return;
                        }
                    
                    10. The last edge case is if the two nodes to be swapped are the same. 
                    While our current implementation will run without error, there’s no point in executing the whole function if it isn’t necessary. 
                    We can add a brief check at the beginning of the function that checks if the data1 is the same as data2, and then return to end the function:

                        if (data1 === data2) {
                            console.log('Elements are the same - no swap needed.');
                            return;
                        }
                
                // Below is the final swapNodes() function. Run it to see how it works. Does it work with edge case inputs?

                Time and Space Complexity
                    The worst case for time complexity in swapNodes() is if both while loops must iterate all the way through to the end (either if there are no matching nodes, or if the matching node is the at the tail). This means that it has a linear big O runtime of O(n), since each while loop has a O(n) runtime, and constants are dropped.
                    There are four new variables created in the function regardless of the input, which means that it has a constant space complexity of O(1).
                
        Two-Pointer Linked List Techniques
            Many common singly linked list problems can be solved by iterating with two pointers. This is sometimes known as the runner technique.
            
            -> Two Pointers Moving in Parallel
                Consider the following problem: Create a function that returns the nth last element of a singly linked list.
                In order to do this, you’ll need some way of knowing how far you are from the end of the list itself. However, in a singly linked list, there’s no easy way to iterate back through the list when you find the end.

                Approaches
                    One thing that might first come to mind is to use an array to store a representation of the linked list. While this approach results in an easy-to-read implementation, it could also use up lots of memory maintaining a dual representation of the same data. If the linked list has one million nodes, we’ll need one million pointers in an array to keep track of it! An approach like this results in an extra O(n) space being allocated.

                        const arrayNthLast = (list, n) => {
                          const linkedListArray = [];
                          let currentNode = list.removeHead();
                          while (currentNode) {
                            linkedListArray.push(currentNode);
                            currentNode = currentNode.getNextNode();
                          }
                          return list[list.length - n];
                        }
                    
                    Instead of creating an entire parallel list, we can solve this problem by using two pointers at different positions in the list but moving at the same rate. As in the previous example, we will use one pointer to iterate through the entire list, but we’ll also move a second pointer delayed n steps behind the first one.

                        nthLastNodePointer = null
                        tailPointer = linked list head
                        count = 0
                        while tail pointer exists
                          move tail pointer forward
                          if count >= n
                            set nthLastNodePointer to head if it's still null or move it forward
                          increment count
                        return nthLastNodePointer

                        Solution:
                            const nthLastNode = (linkedList, n) => {
                                let current = null;
                                let tailSeeker = linkedList.head;
                                let count = 0;
                                while (tailSeeker) {
                                    tailSeeker = tailSeeker.next;
                                    if (count >= n) {
                                        if (!current) {
                                            current = linkedList.head;
                                        }
                                        current = current.next;
                                    }
                                    count++
                                }
                                return current;
                            }
                        
                        We are able to complete this problem efficiently–in O(n) time (we must iterate through the entire list once), 
                        and O(1) space complexity (we always use only three variables no matter what size the list is: two pointers and a counter).

            -> Pointers at Different Speeds
                Another two-pointer technique involves sending pointers through the list at different iteration “speeds”.
                Consider this problem:  Find the middle node of a linked list.
                Approaches
                    As before, it’s possible to find a solution by iterating through the entire list, creating an array representation, and then returning the middle index. But as before, this potentially takes up lots of extra space:
                    
                        create array
                        while the linked list has not been fully iterated through
                            push the current element onto array
                            move forward one node
                        return array[length / 2]
                    
                    Instead, we can use two pointers to move through the list. The first pointer takes two steps through the list for every one step that the second takes, so it iterates twice as fast.
                    
                        fastPointer = list head
                        slowPointer = list head
                        while fastPointer is not null
                            move fastPointer forward
                            if the end of the list has not been reached
                                move fastPointer forward again
                                move slowPointer forward
                        return slowPointer
                    
                    When the first pointer reaches the end of the list, the “slower” second pointer will be pointing to the middle element. 
                    Solution:
                        
                        const findMiddle = linkedList => {
                            let fast = linkedList.head;
                            let slow = linkedList.head;
                            
                            while (fast !== null) {                 // As long as the end of the list is not reached
                                fast = fast.getNextNode();          // Move the fast pointer at least one step
                                if (fast !== null) {                // If it isn't at the end of the list
                                    fast = fast.getNextNode();      // Move both pointers forward once
                                    slow = slow.getNextNode();
                                }
                            }
                            return slow;                            // At this point, the slow pointer is in the middle
                        };
                    
                Half-Speed
                    Another equally valid solution is to move the fast pointer once with each loop iteration but only move the slow pointer every-other iteration.

                        const findMiddleAlternate = linkedList => {
                            let count = 0;
                            let fast = linkedList.head;
                            let slow = linkedList.head;

                            while(fast !== null) {
                                fast = fast.getNextNode();
                                if (count % 2 !== 0) {
                                    slow = slow.getNextNode();
                                }
                                count++;
                            }
                            return slow;
                        }
            
            Conclusions
                Many linked list problems can be solved with the two-pointer technique. If it seems like a linked list problem requires keeping track of multiple positions or creating other data representations (such as using an array), consider whether two pointers iterating in parallel or at different speeds could help solve the problem efficiently. We won’t cover full solutions to these here, but variations on the two-pointer technique can be used to:
                    - Detect a cycle in a linked list
                    - Rotate a linked list by k places
            
    > Queues
        A queue is a linear collection of nodes that exclusively adds (enqueues) nodes to the tail, and removes (dequeues) nodes from the head of the queue. 
        They can be implemented using different underlying data structures, but one of the more common methods is to use a singly linked list, which is what you will be using for your JavaScript Queue class. 
        Think of the queue data structure as an actual queue, or line, in a grocery store. The person at the front gets to leave the line first, and every person who joins the line has to join in the back.

        Queues provide three methods for interaction:
            - Enqueue - adds data to the “back” or end of the queue
            - Dequeue - provides and removes data from the “front” or beginning of the queue
            - Peek - reveals data from the “front” of the queue without removing it
        
        Queues are a First In, First Out or FIFO structure.

        Queues can be implemented using a linked list as the underlying data structure. The front of the queue is equivalent to the head node of a linked list and the back of the queue is equivalent to the tail node.
        Since operations are only allowed affecting the front or back of the queue, any traversal or modification to other nodes within the linked list is disallowed. Since both ends of the queue must be accessible, a reference to both the head node and the tail node must be maintained.
        
        - bounded queue. 
            One last constraint that may be placed on a queue is its length. If a queue has a limit on the amount of data that can be placed into it, it is considered a bounded queue.
            Let’s make our queue a bounded queue. To account for this, we will need to make some modifications to our Queue class so that we can keep track of and limit size where needed.
                We’ll be adding a new property to help us out here:
                    .maxSize, a property that bounded queues can utilize to limit the total node count
                In addition, we will add two new methods:
                    .hasRoom() returns true if the queue has space to add another node
                    .isEmpty() returns true if the size of a queue is 0
        - queue overflow & queue underflow. 
            Similar to stacks, attempting to enqueue data onto an already full queue will result in a queue overflow. If you attempt to dequeue data from an empty queue, it will result in a queue underflow.
            // queue underflow occur in case dequeueing data from an empty queue
            Avoiding Underflow
                There are two conditions when enqueuing and dequeuing that we should be aware of and avoid: underflow and overflow.
                Underflow occurs when we try to remove elements from an already empty queue – we cannot remove a node if it doesn’t exist. Underflow affects queues whether they are bounded or unbounded.
            Avoiding Overflow
                Overflow occurs when we add an element to a queue that does not have room for a new node.
                This condition affects bounded queues because they have fixed sizes they cannot exceed. For unbounded queues, though they don’t have a size restriction, at some point the size of the queue will exceed the available memory we can use to store this queue.

        Queues Review
            Queues:
            - Contain data nodes
            - Support three main operations:
            - Enqueue adds data to the back of the queue
            - Dequeue removes and provides data from the front of the queue
            - Peek provides data on the front of the queue
            - Can be implemented using a linked list or array
            - Bounded queues have a limited size.
            - Enqueueing onto a full queue causes a queue overflow
            - Queues process data First In, First Out (FIFO)
        
        Queues in JavaScript
            As previously mentioned, a queue is a data structure that contains an ordered set of data that follows a FIFO (first in, first out) protocol for accessing that data.
            You can visualize it as a checkout line at a supermarket:
                - The customer at the front of the line (equivalent to the head in a queue) is the first customer to pay for their groceries.
                - Any new customer must go to the back of the line (the tail of the queue) and wait until everyone in front of them has paid for their groceries, (no line cutters allowed in this supermarket!)
                - The supermarket cashier only needs to check out the customer at the front of the line
            Real-life computer science applications of queues are all around us: search algorithms like BFS (breadth-first search), job schedulers that run tasks on our computers, and keyboard processing that interprets our keystrokes are all queue based.
            We’ll also set up a few helper methods that will help us keep track of the queue size in order to prevent queue overflow and underflow.
            To do this, we’ll make use of some data structures you’ve already seen: nodes and linked lists. 

            // Node.js
            class Node {
                constructor(data) {
                    this.data = data;
                    this.next = null;
                }
                setNextNode(node) {
                    if (!(node instanceof Node)) {
                        throw new Error('Next node must be a member of the Node class');
                    }
                    this.next = node;
                }
                setNext(data) {
                    this.next = data;
                }
                getNextNode() {
                    return this.next;
                }
            }
            module.exports = Node;

            // LinkedList.js
            const Node = require('./Node');
            class LinkedList {
                constructor() {
                    this.head = null;
                }
                addToHead(data) {
                    const nextNode = new Node(data);
                    const currentHead = this.head;
                    this.head = nextNode;
                    if (currentHead) {
                        this.head.setNextNode(currentHead);
                    }
                }
                addToTail(data) {
                    let lastNode = this.head;
                    if (!lastNode) {
                        this.head = new Node(data);
                    } else {
                        let temp = this.head;
                        while (temp.getNextNode() !== null) {
                            temp = temp.getNextNode();
                        }
                        temp.setNextNode(new Node(data));
                    }
                }
                removeHead() {
                    const removedHead = this.head;
                    if (!removedHead) {
                        return;
                    }
                    this.head = removedHead.getNextNode();
                    return removedHead.data;
                }
                printList() {
                    let currentNode = this.head;
                    let output = '<head> ';
                    while (currentNode !== null) {
                        output += currentNode.data + ' ';
                        currentNode = currentNode.next;
                    }
                    output = output.concat("<tail>");
                    console.log(output);
                }
            }
            module.exports = LinkedList;

            // Queue.js
            const LinkedList = require('./LinkedList');

            class Queue {
                constructor(maxSize = Infinity) {
                    this.queue = new LinkedList();
                    this.size = 0;
                    this.maxSize = maxSize;  // unbounded queue
                }
                // hasRoom() and isEmpty() methods for Bounded Queues
                hasRoom(){                          // used later to Avoid Overflow
                    return this.size < this.maxSize;
                    // if(this.size < this.maxSize){
                    //     return true
                    // } else {
                    //     return false;
                    // }
                }
                isEmpty(){                          // used later to Avoid Underflow
                    return this.size === 0;
                    // if(this.size === 0){
                    //     return true;
                    // } else {
                    //     return false;
                    // }
                }
                enqueue(data) {
                    if(this.hasRoom()){                         // Avoiding Overflow
                        this.queue.addToTail(data);
                        this.size++;
                        // console.log(`Added ${data} to queue! Queue size is now ${this.size}.`);
                    } else {
                        throw new Error('Queue is full!')
                    }
                }
                dequeue(){
                    if (!this.isEmpty()) {                      // Avoiding Underflow
                        const data = this.queue.removeHead();
                        this.size--;
                        // console.log(`Removed ${data} from queue! Queue size is now ${this.size}.`);
                        return data;
                    } else {
                        throw new Error("Queue is empty!");
                    }
                }
            }
            module.exports = Queue;

            const restaurantOrders = new Queue();
            console.log(`restaurantOrders has ${restaurantOrders.size} nodes`)
            
            restaurantOrder.enqueue('apple pie');
            restaurantOrder.enqueue('roast chicken');
            restaurantOrder.enqueue('quinoa salad');

            console.log('\nFood preparing...\n')
            restaurantOrder.dequeue();
            restaurantOrder.dequeue();
            restaurantOrder.dequeue();
            console.log('All orders ready!')

    > Stacks
        Like a queue, a stack is a linear collection of nodes that adds (pushes) data to the head, or top, of the stack. However, unlike a queue, a stack removes data (pops) from the head of the stack. Think of it as a stack of books, where you can only pick up the top book, and add a new book to the top.
        A real-world computing example of a stack is a web browser’s back/forward function.
        
        A stack is a data structure which contains an ordered set of data.
        Stacks provide three methods for interaction:
            - Push - adds data to the “top” of the stack
            - Pop - returns and removes data from the “top” of the stack
            - Peek - returns data from the “top” of the stack without removing it

        This is a Last In, First Out or LIFO structure.

        Stacks Implementation
            Stacks can be implemented using a linked list as the underlying data structure because it’s more efficient than a list or array.
            Depending on the implementation, the top of the stack is equivalent to the head node of a linked list and the bottom of the stack is equivalent to the tail node.
            A constraint that may be placed on a stack is its size. This is done to limit and quantify the resources the data structure will take up when it is “full”.
            - stack overflow
                Attempting to push data onto an already full stack will result in a stack overflow. 
            - stack underflow
                Similarly, if you attempt to pop data from an empty stack, it will result in a stack underflow.
        
        Stacks Review
            Stacks:
            - Contain data nodes
            - Support three main operations
                - Push adds data to the top of the stack
                - Pop removes and provides data from the top of the stack
                - Peek reveals data on the top of the stack
            - Implementations include a linked list or array
            - Can have a limited size
                - Pushing data onto a full stack results in a stack overflow
            - Stacks process data Last In, First Out (LIFO)
        
            // Stack.js
            const LinkedList = require('./LinkedList');
            class Stack {
                constructor(maxSize = Infinity) {
                    this.stack = new LinkedList();
                    this.size = 0                       // Stacks Javascript Size
                    this.maxSize = maxSize
                }
                hasRoom() {
                    return (this.size < this.maxSize);  
                }
                isEmpty() {
                    return (this.size === 0);  
                }
                peek(){
                    if(!this.isEmpty()){
                        return this.stack.head.data;
                    } else {
                        return null;
                    } 
                }
                push(value){
                    if (this.hasRoom()) {
                        this.stack.addToHead(value);
                        this.size++;      
                    } else {
                        throw new Error('Stack is full');
                    }
                }
                pop(){
                    if (!this.isEmpty()) {
                        const value = this.stack.removeHead();
                        this.size--;
                        return value;
                    } else {
                        throw new Error('Stack is empty!');
                    }
                }
            }
            module.exports = Stack;

        Project: Web Navigator.

3. Hash Maps
    Moving on from the linear data structures, now it’s time to focus on hash maps! Hash maps map keys to their related values, and are one of the most efficient data structures when it comes to retrieving stored data. This is because the key associated with every value added allows for faster retrieval later on. When you come across a coding problem that requires you to store and retrieve data, keep in mind that hash maps will often be the most efficient data structure for that scenario.
    
    Tables
        A data structure’s main utility is allowing for data to be represented in a way that resembles the way people will use that data. In some cases, the primary function of that data is that it will be sequenced through like a list and so we use a data structure that allows for easier iteration, like a linked list. In others, the usefulness comes from specifying interrelationships within the data.
        In the case of tabular data there is a relationship between the elements of a row. Each column corresponds to a different feature of the row. Let’s consider the following table:
            State       State Flower
            NY          Rose
            HI          Hibiscus
        Each State on the left corresponds to a specific State Flower given on the right. For instance, “New York” corresponds to “Rose”. This kind of table, with only two columns, represents a special relationship that mathematicians would call a “map”. This table maps states to state flowers, but many other relationships can be modeled with maps.
    
    Maps
        In order for a relationship to be a map, every key that is used can only be the key to a single value. 
        There doesn’t need to be a value for every possible key, there just can’t be more than one value for a given key. 
    
    Hash Map Methodology
        In the case of a map between two things, we don’t really care about the exact sequence of the data. 
        We only care that a given input, when fed into the map, gives the accurate output.
        - hashing function, or a hash function.
            Imagine we want our computer to remember that our good friend Joan McNeil is a Libra. We take her name, and we turn that name into a number. Let’s say that the number we correspond with the name “Joan McNeil” is 17. We find the 17th index of the array we’re using to store our map and save the value (Libra) there.
            How did we get 17, though? We use a special function that turns data like the string “Joan McNeil” into a number. This function is called a hashing function, or a hash function. Hashing functions are useful in many domains, but for our data structure the most important aspect is that a hashing function returns an array index as output.
    
    Hash Functions
        A hash function takes a string (or some other type of data) as input and returns an array index as output. In order for it to return an array index, our hash map implementation needs to know the size of our array. If the array we are saving values into only has 4 slots, our hash map’s hashing method should not return an index bigger than that.
        In order for our hash map implementation to guarantee that it returns an index that fits into the underlying array, the hash function will first compute a value using some scoring metric: this is the hash value, hash code, or just the hash. Our hash map implementation then takes that hash value mod the size of the array. This guarantees that the value returned by the hash function can be used as an index into the array we’re using.
        It is actually a defining feature of all hash functions that they greatly reduce any possible inputs (any string you can imagine) into a much smaller range of potential outputs (an integer smaller than the size of our array). For this reason hash functions are also known as compression functions.
        Much like an image that has been shrunk to a lower resolution, the output of a hash function contains less data than the input. Because of this hashing is not a reversible process. With just a hash value it is impossible to know for sure the key that was plugged into the hashing function.
    
    How to Write a Hash Function
        Key             garnet
        Hashed into     ['g', 'a', 'r', 'n', 'e', 't']
        Code Point      ['103', '97', '114', '110', '101', '116']
        Add Them Up     103 + 97 + 114 + 110 + 101 + 116 =
        Hash Value      641
    
    Basic Hash Maps
        Main ingredients for a hash map:
        - some sort of associated data that we’re hoping to preserve.
        - array of a fixed size to insert our data into.
        - a hash function that translates the keys of our array into indexes into the array
        
        The storage location at the index given by a hash is called the hash bucket.
    
    Collisions
        Remember hash functions are designed to compress data from a large number of possible keys to a much smaller range. Because of this compression, it’s likely that our hash function might produce the same hash for two different keys. This is known as a hash collision. 
        There are several strategies for resolving hash collisions:
            - separate chaining - avoids collisions by updating the underlying data structure. Instead of an array of values that are mapped to by hashes, it could be an array of linked lists!
                A hash map with a linked list separate chaining strategy follows a similar flow to the hash maps that have been described so far. The user wants to assign a value to a key in the map. The hash map takes the key and transforms it into a hash code. The hash code is then converted into an index to an array using the modulus operation. If the value of the array at the hash function’s returned index is empty, a new linked list is created with the value as the first element of the linked list. If a linked list already exists at the address, append the value to the linked list given.
                This is effective for hash functions that are particularly good at giving unique indices, so the linked lists never get very long. But in the worst-case scenario, where the hash function gives all keys the same index, lookup performance is only as good as it would be on a linked list. Hash maps are frequently employed because looking up a value (for a given key) is quick. Looking up a value in a linked list is much slower than a perfect, collision-free hash map of the same size. A hash map that uses separate chaining with linked lists but experiences frequent collisions loses one of its most essential features.
                Saving Keys
                    A hash collision resolution strategy like separate chaining involves assigning two keys with the same hash to different parts of the underlying data structure. How do we know which values relate back to which keys? If the linked list at the array index given by the hash has multiple elements, they would be indistinguishable to someone with just the key.
                    If we save both the key and the value, then we will be able to check against the saved key when we’re accessing data in a hash map. By saving the key with the value, we can avoid situations in which two keys have the same hash code where we might not be able to distinguish which value goes with a given key.
                    Now, when we go to read or write a value for a key we do the following: calculate the hash for the key, find the appropriate index for that hash, and begin iterating through our linked list. For each element, if the saved key is the same as our key, return the value. Otherwise, continue iterating through the list comparing the keys saved in that list with our key.
            - open addressing
                In open addressing we stick to the array as our underlying data structure, but we continue looking for a new index to save our data if the first result of our hash function has a different key’s data.
                A common open method of open addressing is called probing. Probing means continuing to find new array indices in a fixed sequence until an empty index is found.
                Suppose we want to associate famous horses with their owners. We want our first key, “Bucephalus”, to store our first value, “Alexander the Great”. Our hash function returns an array index 3 and so we save “Alexander the Great”, along with our key “Bucephalus”, into the array at index 3.
                After that, we want to store “Seabiscuit”s owner “Charles Howard”. Unfortunately “Seabiscuit” also has a hash value of 3. Our probing method adds one to the hash value and tells us to continue looking at index 4. Since index 4 is open we store “Charles Howard” into the array at index 4. Because “Seabiscuit” has a hash of 3 but “Charles Howard” is located at index 4, we must also save “Seabiscuit” into the array at that index.
                When we attempt to look up “Seabiscuit” in our Horse Owner’s Hash Map, we first check the array at index 3. Upon noticing that our key (Seabiscuit) is different from the key sitting in index 3 (Bucephalus), we realize that this can’t be the value we were looking for at all. Only by continuing to the next index do we check the key and notice that at index 4 our key matches the key saved into the index 4 bucket. Realizing that index 4 has the key “Seabiscuit” means we can retrieve the information at that location, Seabiscuit’s owner’s name: Charles Howard.
                Other Open Addressing Techniques
                    There are more sophisticated ways to find the next address after a hash collision, although anything too calculation-intensive would negatively affect a hash table’s performance. Linear probing systems, for instance, could jump by five steps instead of one step.
                    In a quadratic probing open addressing system, we add increasingly large numbers to the hash code. At the first collision we just add 1, but if the hash collides there too we add 4 ,and the third time we add 9. Having a probe sequence change over time like this avoids clustering.
                    Clustering is what happens when a single hash collision causes additional hash collisions. Imagine a hash collision triggers a linear probing sequence to assigns a value to the next hash bucket over. Any key that would hash to this “next bucket” will now collide with a key that, in a sense, doesn’t belong to that bucket anyway.
                    As a result the new key needs to be assigned to the next, next bucket over. This propagates the problem because now there are two hash buckets taken up by key-value pairs that were assigned as a result of a hash collision, displacing further pairs of information we might want to save to the table.
    
    Review
        A hash map is:
            - Built on top of an array using a special indexing system.
            - A key-value storage with fast assignments and lookup.
            - A table that represents a map from a set of keys to a set of values.
        Hash maps accomplish all this by using a hash function, which turns a key into an index into the underlying array.
        A hash collision is when a hash function returns the same index for two different keys.
        There are different hash collision strategies. Two important ones are separate chaining, where each array index points to a different data structure, and open addressing, where a collision triggers a probing sequence to find where to store the value for a given key.

    Intro to Hash Maps
        Hash maps are data structures that serve as efficient key-value stores. They are capable of assigning and retrieving data in the fastest way possible. This is because the underlying data structure that hash maps use is an array.
        A value is stored at an array index determined by plugging the key into a hash function. Because we always know exactly where to find values in a hash map, we have constant access to any of the values it contains.
        This quick access to values makes a hash map a good choice of data structure whenever we need to store a lot of values but need fast look-up time.
        In JavaScript, objects are often used to map keys to values as in a hash map, but in this lesson, you’ll create your own implementation of a hash map by building out a HashMap class. You’ll build methods to hash and compress a given key, assign an index at which to store a value, and retrieve that value.
        To implement a hash map, the HashMap constructor method will create an empty array that will hold values. A hashing function will return an index in the array where the value will be stored. While going through the following exercises, remember that the purpose of this lesson is to gain a deeper understanding of the data structure rather than creating a production-quality data structure.

            class HashMap {
                constructor(size = 0) {
                    this.hashmap = new Array(size)
                        .fill(null)
                        .map(() => new LinkedList());                   // Collisions: separate chaining.   Instead of an empty array, new hash maps will have an internal array filled with empty linked lists.
                }
                hash(key) {                                             // Hashing
                    let hashCode = 0;
                    for (let i = 0; i < key.length; i++) {
                        hashCode += hashCode + key.charCodeAt(i);
                    }
                    hashCode = hashCode % this.hashmap.length           // Compression
                    return hashCode;
                }
                assign(key, value) {                                    // Assign
                    const arrayIndex = this.hash(key);
                    // this.hashmap[arrayIndex] = value;                // without Collisions.
                    const linkedList = this.hashmap[arrayIndex];        // Collisions: Assigning (separate chaining)
                    if (linkedList.head === null) {
                        linkedList.addToHead({ key, value });
                        return;
                    } 
                    let current = linkedList.head;                      // Collisions: Looping (separate chaining)
                    while (current) {
                        if (current.data.key === key) {
                            current.data = { key, value };
                        }
                        if (!current.getNextNode()) {
                            const newNode = new Node({ key, value });
                            current.setNextNode(newNode);
                            break;
                        }
                        current = current.getNextNode();
                    }
                }
                retrieve(key){                                          // Retrieve
                    const arrayIndex = this.hash(key);
                    // return this.hashmap[arrayIndex];                 // without Collisions.
                    let current = this.hashmap[arrayIndex].head;        // Collisions: Retrieving
                    while (current) {
                        if (current.data.key === key) {
                            return current.data.value;
                        }
                        current = current.next;
                    }
                    return null;
                }
            }

            let myHashMap = new HashMap(3);
            console.log(myHashMap.hash('id'));
            console.log(myHashMap.hash('id'));

            const employees = new HashMap(3);
            employees.assign('34-567', 'Mara');
            console.log(employees.hashmap);

            const glossary = new HashMap(3);
            glossary.assign('semordnilap', 'Words that form different words when reversed');
            console.log(glossary.retrieve('semordnilap'))

            const parkInventory = new HashMap(2);                       // -> Collisions
            parkInventory.assign('reed', 'marsh plant');
            parkInventory.assign('deer', 'forest animal');

            module.exports = HashMap;        
    
    Hashing     (see hash() method above)
        The hashing function is the secret to efficiently storing and retrieving values in a hash map. A hashing function takes a key as input and returns an index within the hash map’s underlying array.
        This function is said to be deterministic. That means the hashing function must always return the same index when given the same key. This is important because we will need to hash the key again later to retrieve the stored value. We won’t be able to do this unless our hashing function behaves in a predictable and consistent way.
        Getting an integer representing an index can be done by summing the character codes, or integer representation, of all the characters in the key, a string. A variable can be used to keep track of the running total of the character codes until .hash() is finished looping over the key and the sum can be returned.
        The code for the hashing function should look something like this:
            
            declare hashCode variable with value of 0
            for each character in the key
                add the character code value to hashCode
            return hashCode

    Compression
        The current hashing function will return a wide range of integers — some of which are not indices of the hash map array. To fix this, we need to use compression.
        Compression means taking some input and returning an output only within a specific range.
        In our hash map implementation, we’re going to have our hashing function handle compression in addition to hashing. This means we’ll add an additional line of code to compress the hashCode before we return it.
        The updated .hash() should follow these steps:

            initialize hashCode variable to 0
            for each character in the key
                add the character code and hashCode to hashCode
            return compressed hashCode
    
    Assign
        We now have everything we need to find a place in the hash map array to store a value. The only thing left to do is assign the value to the index we generated. A method, .assign() will handle the logic needed to take in a key-value pair and store the value at a particular index.
        A general outline of how .assign() will work is this:

            store the hashed key in a variable arrayIndex
            assign the value to the element at arrayIndex in the hash map

    Retrieve
        To be a fully functional hash map, we have to be able to retrieve the values we are storing. To implement retrieval for our hash map we’ll create a new HashMap method, .retrieve().
        This method will make use of .hash()‘s deterministic nature to find the value we’re looking for in the hash map.

    Collisions: Assigning
        Our first step in implementing a collision strategy is updating our constructor and .assign() method to use linked lists and nodes inside the hashmap array. This will allow us to store multiple values at the same index by adding new nodes to a linked list instead of overwriting a single value. This strategy of handling collisions is called separate chaining.
        A collision-proof .assign() should look like this to start:
        
            store the hashed key in a variable arrayIndex
            store linked list at arrayIndex in a variable linkedList
            if linked list is empty
                add the key-value pair to the linked list as a node

    Collisions: Looping
        We’ve added code to .assign() that takes care of an empty list, but what happens when there is a collision and there are already values stored at a particular index?
        If there are already values stored in nodes at an index, we need to loop over each node in the list in order to determine how to proceed.
        The two possibilities we’ll encounter while looping are:
        The key we are looking for and the key of the current node is the same, so we should overwrite the value
        No node in the linked list matches the key, so we should add the key-value pair to the list as the tail node
        After both cases, if we haven’t already exited the loop, we should reset the loop’s condition.
        With this in mind, the .assign() code for looping should look like this:

            store the head node of the linked list in a variable current
            while there is a current node
                if the current node's key is the same as the key
                    store the key and value in current
                if the current node is the tail node
                    store the key-value pair in the node after current
                    exit the loop      
                set current to the next node

    Collisions: Retrieving
        When we retrieve hash map values we also need to be aware that different keys could point to the same array index leading us to retrieve the wrong value.
        To avoid this, we’ll search through the linked list at an index until we find a node with a matching key. If we find the node with the correct key, we’ll return the value otherwise we’ll return null.
        The .retrieve() method will follow this logic:

            store the hashed key in the variable arrayIndex
            store the head node of a list in the constant current
            while there is a valid node
                if the current node's key matches the key
                    return the current node's value
                set current to the next node in the list
            return null
    

4. Algorithmic Concepts
    > Recursion
        It will also be used in some of the traversal and sort algorithms that you will see later!
        Recursion Outline
            Recursion is a strategy for solving problems by defining the problem in terms of itself. For example, to sum the elements of a list we would take the first element and add it to the sum of the remaining elements.
            In programming, recursion means a function definition will include an invocation of the function within its own body. 
                pseudo-code example for a recursion approach:
                    define function, speller
                        if there are no more letters
                            print "all done"
                        print the first letter
                        invoke speller with the given name minus the first letter

                pseudo-code for an iterative approach:
                     define function, speller
                        for each letter in the name argument
                            print the letter
                        print "all done"
        
        Call Stacks and Execution Frames
            Recursion:
                - call stack            - is a DS typically abstracted away from us which stores f-n calls in programs.
                - execution context     - contains the variables within each recursive f-n call.
                Example:
                    sum_list(arr)
                        if arr empty
                            return 0
                        return first + sum_list(arr-1)
                Call Stack
                S_L         -> 0                // empty list   - we're satisfying the base case, no futher computation is needed. Now pop this f-n from call stack and show its return value.
                S_L 7       -> 7 + 0            // then jumping into execution context of this f-n where we're waiting for recursive call
                S_l 6,7     -> 6 + 7 + 0        // f-n call
                S_L 5,6,7   -> 5 + 6 + 7 + 0 = 18

        Base Case and Recursive Step
            Recursion has two fundamental aspects: the base case and the recursive step.
            When using iteration, we rely on a counting variable and a boolean condition. For example, when iterating through the values in a list, we would increment the counting variable until it exceeded the length of the dataset.
            Recursive functions have a similar concept, which we call the base case. The base case dictates whether the function will recurse, or call itself. Without a base case, it’s the iterative equivalent to writing an infinite loop.
            Because we’re using a call stack to track the function calls, your computer will throw an error due to a stack overflow if the base case is not sufficient.
            The other fundamental aspect of a recursive function is the recursive step. This portion of the function is the step that moves us closer to the base case.
            In an iterative function, this is handled by a loop construct that decrements or increments the counting variable which moves the counter closer to a boolean condition, terminating the loop.
            In a recursive function, the “counting variable” equivalent is the argument to the recursive call. If we’re counting down to 0, for example, our base case would be the function call that receives 0 as an argument. We might design a recursive step that takes the argument passed in, decrements it by one, and calls the function again with the decremented argument. In this way, we would be moving towards 0 as our base case.
            Analyzing the Big O runtime of a recursive function is very similar to analyzing an iterative function. Substitute iterations of a loop with recursive calls.
            For example, if we loop through once for each element printing the value, we have a O(N) or linear runtime. Similarly, if we have a single recursive call for each element in the original function call, we have a O(N) or linear runtime.
        
        Recursion in JS
            Recursion is a powerful tool for solving problems that require the execution of a similar action multiple times until a certain condition is met. For many problems, a recursive solution will result in fewer lines of code and will be easier to comprehend than a solution that uses a for or while loop.

                const iterativeFactorial = (n) => {
                    let result = 1;
                    while(n > 0) {
                        result *= n;
                        n -= 1;
                    }
                    return result;
                }
                const fourFactorial = iterativeFactorial(4)
                console.log(fourFactorial)
                module.exports = {iterativeFactorial};

            Recursion is a computational approach where a function calls itself from within its body. Programmers use recursion when they need to perform the similar action multiple times in a row until it reaches a predefined stopping point, also known as a base case.

                const recursiveFactorial = (n) => {
                    if(n===0){                                      // Base Case
                        return 1;
                    }
                    if (n>0) {                                      // We call this 'if' block the recursive case.
                        // console.log(`Execution context: ${n}`);
                        return n * recursiveFactorial(n - 1);
                    }
                }
                const recursiveSolution = recursiveFactorial(4);
                console.log(recursiveSolution);
                module.exports = {recursiveFactorial};
            
            Recursive Case  – the conditions under which the fn will perform an action and call itself.
            Base Case       - the conditions under which the fn returns a value without making any additional calls to itself.

            Example:
                // Find a node in a linked list:
                class LinkedList {

                    findNodeRecursively(data, currentNode = this.head) {
                        if (currentNode === null) {                 // Base case 2 – return null if the end of the linked list is reached.
                            return null;
                        } else if (currentNode.data === data) {     // Base case 1 – return the current node if it matches the data argument.
                            return currentNode;
                        } else {                                    // Recursive Case – return a call to .findNodeRecursively() with the next node as an argument.
                            return this.findNodeRecursively(data, currentNode.next);
                        }
                    }
                    
                    findNodeIteratively(data) {                     // using an iterative approach
                        let currentNode = this.head;
                        while (currentNode !== null) {
                            if (currentNode.data === data) {
                                return currentNode;
                            }
                            currentNode = currentNode.next;
                        }
                        return null;
                    }
                }

    > Asymptotic Notation
        Computers seem to take no time evaluating programs, but when scaling programs to deal with massive amounts of data, writing efficient code becomes the difference between success and failure. 
        In computer science, we define how efficient a program is by its runtime.
        We can’t just time the program, however, because different computers run at different speeds. 
        My dusty old PC does not run as fast as your brand new laptop. 
        Programming is also done in many different languages, how do we account for that in the runtime? 
        We need a general way to define a program’s runtime across these variable factors. 
        We do this with Asymptotic Notation.

        -> With asymptotic notation, we calculate a program’s runtime by looking at how many instructions the computer has to perform based on the size of the program’s input. 
        For example, if I were calculating the maximum element in a collection, I would need to examine each element in the collection. That examining step is the same regardless of the language used, or the CPU that’s performing the calculation. In asymptotic notation, we define the size of the input as N. I may be looking through a collection of 10 elements, or 100 elements, but we only need to know how many steps are performed relative to the input so N is used in place of a specific number. If there is a second input, we may define the size of that input as M.

        -> There are varieties of asymptotic notation that focus on different concerns. 
            Some will communicate the best case scenario for a program. 
                For example, if we were searching for a value within a collection, the best case would be if we found that element in the first place we looked. 
            Another type will focus on the worst case scenario, such as if we searched for a value, looked in the entire dataset and did not find it. 
                Typically programmers will focus on the worst case scenario so there is an upper bound of runtime to communicate. It’s a way of saying “things may get this bad, or slow, but they won’t get worse!”

        There are three different ways we could describe the runtime of this program: 
            - big Theta or Θ(N^2),  - same runtime
                We use big Theta when a program has only one case in term of runtime.
                The number of instructions the computer has to perform is based on how many iterations the loop will do because if the loop does more iterations, then the computer will perform instructions.
                As we can see in every case, with a list of size N, the program has a runtime of N because the program has to print a value N times. Thus, we would say the runtime is Θ(N).
                Let’s look at a more complicated example. In the following pseudocode program, the function takes in an integer, N, and counts the number of times it takes for N to be divided by 2 until N reaches 1.
                    Function that has integer input N:
                        Set a count variable to 0
                        Loop while N is not equal to 1:
                            Increment count
                            N = N/2
                        Return count
                As we can see, in every case, with an integer N, the loop will iterate log2(N) times. However, because we drop constants in asymptotic notation, we would say that the runtime of this program is Θ(log N).

            - big O or O(N^2),      - worst-case runtime
            - big Omega or Ω(N^2).  - best-case runtime

        What happens when there are multiple runtime cases for a single program? 
            Sometimes, a program may have a different runtime for the best case and worst case. 
            For instance, a program could have a best case runtime of Θ(1) and a worst case of Θ(N). 
            We use a different notation when this is the case. 
            We use big Omega or Ω to describe the best case and big O or O to describe the worst case. 
            Take a look at the following pseudocode that returns True if 12 is in the list and False otherwise:
                Function with input that is a list of size N:
                    For each value in the list:
                        If value is equal to 12:
                            Return True
                    Return False
            How many times will the loop iterate? Let’s take a list of size 1000. If the first value in the list was 12, then the loop would only iterate once. However, if 12 wasn’t in the list at all, the loop would iterate 1000 times. If the input was a list of size N, the loop could iterate anywhere from 1 to N times depending on where 12 is in the list (or if it’s in the list at all). 
            Thus, in the best case, it has a constant runtime and in the worst case it has a linear runtime.
            There are many ways we could describe the runtime of this program:
                - This program has a best case runtime of Θ(1).
                - This program has a worst case runtime of Θ(N).
                - This program has a runtime of Ω(1).
                - This program has a runtime O(N).
            You may be tempted to say the following:
                - This program has a runtime of Θ(N).
            However, this is not true because the program does not have a linear runtime in every case, only the worst case.
            In fact, when describing runtime, people typically discuss the worst case because you should always prepare for the worst case scenario! 
            Often times, in technical interviews, they will only ask you for the big O of a program.

        Common Runtimes
            Θ(1).       This is constant runtime. This is the runtime when a program will always do the same thing regardless of the input. For instance, a program that only prints “hello, world” runs in Θ(1) because the program will always just print “hello, world”.
            Θ(log N).   This is logarithmic runtime. You will see this runtime in SEARCH ALGORITHMS.
            Θ(N).       This is linear runtime. You will often see this when you have to ITERATE through an entire dataset.
            Θ(N*logN).  You will see this runtime in SORTING ALGORITHMS.
            Θ(N^2).      This is an example of a polynomial(quadratic) runtime. You will see this runtime when you have to search through a two-dimensional dataset (like a MATRIX) or NESTED LOOPS.
            Θ(2^N).      This is exponential runtime. You will often see this runtime in RECURSIVE algorithms (Don’t worry if you don’t know what that is yet!).
            Θ(N!).      This is factorial runtime. You will often see this runtime when you have to generate all of the different permutations of something. For instance, a program that generates all the different ways to order the letters “abcd” would run in this runtime.
        
        Adding Runtimes
            Sometimes, a program has so much going on that it’s hard to find the runtime of it. 
            Take a look at the pseudocode program that first prints all the positive values up to N and then returns the number of times it takes to divide N by 2 until N is 1.
                Function that takes a positive integer N:
                    Set a variable i equal to 1
                    Loop until i is equal to N:
                        Print i
                        Increment i

                    Set a count variable to 0
                    Loop while N is not equal to 1:
                        Increment count
                        N = N/2
                    Return count
            Rather than look at this program all at once, let’s divide into two chunks: the first loop and the second loop.
            In the first loop, we iterate until we reach N. Thus the runtime of the first loop is Θ(N).
            However, the second loop, as demonstrated in a previous exercise, runs in Θ(log N).
            Now, we can add the runtimes together, so the runtime is Θ(N) + Θ(log N).
            However, when analyzing the runtime of a program, we only care about the slowest part of the program, and because Θ(N) is slower than Θ(log N), we would actually just say the runtime of this program is Θ(N). 
            It is also appropriate to say the runtime is O(N) because if it runs in Θ(N) for every case, then it also runs in Θ(N) for the worst case. Most of the time people will just use big O notation.

        Review
            - We use asymptotic notation to describe the runtime of a program. The three types of asymptotic notation are big Theta, big Omega, and big O.
            - We use big Theta (Θ) to describe the runtime if the runtime of the program is the same in every case.
            - The different common runtimes from fastest to slowest are: Θ(1), Θ(log N), Θ(N), Θ(N log N), Θ(N2), Θ(2N), Θ(N!).
            - We use big Omega (Ω) to describe the best-case running time of a program.
            - We use big O (O) to describe the worst-case running time of a program.
            - We typically describe a program’s running time in terms of big O.
            - When finding the runtime of a program with multiple steps, you can divide the program into different sections and add the runtimes of the various sections. You can then take the slowest runtime and use that runtime to describe the entire program.
            - When analyzing the runtime of a program, we care about which part of the program is the slowest.

        Asymptotic Notation: JavaScript
            When analyzing the runtime of a function, it’s necessary to check the number of iterations the loop will perform based on the size of the input.
            
            - divideByTwo() has a big O runtime of log n because the function divides n by two every iteration, and terminates when n is 1. countIterations counts how many times the while loop runs, and you can see in the output that it is log2(n). 
            Since we drop constants for asymptotic notation, the big O runtime is just log n.
            - DS. The function, findMax(), takes in list as an input.
                The big O runtime is n since you iterate through the list one time.
                    function findMax(list) {
                        let current = list.head;
                        let max = current.data;
                        while (current.getNextNode() !== null) {
                            current = current.getNextNode();
                            let val = current.data;
                            if (val > max) {
                                max = val;
                            }
                        }
                        return max;
                    }
            - Sorting a Linked List
                Since there are nested while loops (one in findMax() and one in sortLinkedList()), the big O runtime is n^2.
                There are many ways to sort a linked list, but one way is as follows:
                    - Instantiate a new linked list
                    - Find the maximum value of the linked list input
                    - Insert the maximum to the beginning of the new linked list
                    - Remove the maximum value from the linked list input
                    - Repeat steps 2-4 until the linked list input is empty
                    - Return the new linked list

                function sortLinkedList(list) {
                    let newList = new LinkedList();
                    while (list.head !== null) {
                        let currentMax = findMax(list);
                        list.remove(currentMax);
                        newList.addToHead(currentMax);
                    }
                    return newList;
                }
            - Stack Runtimes vs Queue Runtimes
                - Removing the First Value Added to a Queue
                    The big O for the queue is O(1) because the element is at the head of the queue, so removing it is only one step. 
                - Removing the First Value Added to a Stack
                    On the other hand, since the element is at the bottom of the stack, removing it from the stack requires iterating through the whole stack.
                - While finding the first value added to a queue has a better big O runtime than doing so in a stack, consider finding the last value added. 
                In a queue, we will have to iterate through the entire queue to retrieve the element at the end. 
                This will be a big O runtime of O(n). 
                On the other hand, the last value added to a stack is the value at the top of the stack, so removing it will just be a big O runtime of O(1).
            - Hash Map Runtimes vs Linked List Runtimes
                - Retrieving an Element from a Linked List
                    To find an element in a linked list, we will have to search through the entire list to see if the element is there. 
                    Iterating through the list means that this process has a big O runtime of O(n).
                - Retrieving an Element from a Hash Map
                    Retrieving an element from a hash map is more efficient, due to its structure. 
                    Hash maps store information using key-value pairs, which means that every value is linked to a unique key. 
                    In order to find the value from the key, it uses the hash function, which has a big O runtime of O(1). 
                    If you don’t have to search through the entire data structure, retrieving an element from a hash map is faster than retrieving an element from a linked list.
                    - Separate Chaining
                        e.g. O(n) multiple steps required to retrieve an element from a hash map that uses separate chaining
                            The worst case would be that all elements in the hash map hashed to the same index and are in one linked list with the element you’re looking for at the end of the list. To find it, you would have to iterate through the list, which means the big O runtime is O(n).
                        One way to solve hash map collisions is to create a linked list at the array index where the collision occurred. 
                        All elements that hash to the same index will be in that list. 
                        This means that to find an element in a hash map that uses separate chaining, you must first find the correct index, and then search through the list at that index (if there is more than one element).
                    - Open Addressing
                        Another way to solve hash map collisions is to simply move down the array until you find an open index, and place the element there. This is a type of open addressing that is called linear probing. When retrieving an element from a hash map that uses linear probing, the worst case would be if the element hashes to the first index, but is actually at the last index. Since you would have to search through the entire array, the big O runtime for retrieving an element from this kind of hash map is O(n).
            
            Example:    O(1)
                function makeSum(num1, num2) {  // This is a mathematical operation, so the steps the function performs will not increase with larger inputs.
                    return num1 + num2;
                }

        Space Complexity
            Asymptotic notation is often used to describe the runtime of a program or algorithm, but it can also be used to describe the space, or memory, that a program or algorithm will need. 
                function addNumbers(a, b) {
                    return a + b;
                }
                This function has a space complexity of O(1), because the amount of space it needs will not change based on the input. 
            While this function also has a constant runtime of O(1), most functions do not have matching space and time complexities:
                function simpleLoop(inputArray) {
                    for (let i = 0; i < inputArray.length; i++) { 
                        console.log(i);
                    }
                }
            A recursive function that is passed the same array or object in each call doesn’t add to the space complexity if the array or object is passed by reference (which it is in JavaScript).
            Like with time complexity, space complexity denotes space growth in relation to the input size. It’s also important to note that space complexity usually refers to any additional space that will be needed, and doesn’t count the space of the input. So a function could have 10 arrays passed into it, but if all it does inside is print 'Hello World!', then it still takes O(1) space.

            Example:
                function doubleArray(inputArray) { // Returns an array that is the double of the input array
                    const doubledArray = [];
                    for (let i = 0; i < inputArray.lenght; i++) {
                        doubledArray[i] = 2 * inputArray[i];
                    }
                    return doubledArray;
                }

                function findMin(inputArray) { // Returns the smallest element in the array
                    let min = inputArray[0];
                    for (let i = 0; i < inputArray.length; i++) {
                        if (inputArray[i] < min) {
                            min = inputArray[i];
                        }
                    }
                    return min;
                }
                O(n) - doubleArray() creates a new array that matches the size of the input array, so the space needed for this function will change as the size of the input array changes. 
                O(1) - findMin() only creates one new variable regardless of the input, so its size is constant.

                Space complexity is important to consider alongside time complexity when comparing data structures and algorithms. 
                While two functions may have very similar runtimes, one could use less space. 
                Consider the doubleArray() function from above. It has a runtime of O(n), and takes O(n) space. 
                Could we optimize it to have a better space complexity?

                    function doubleInPlace(inputArray) { 
                        for (let i = 0; i < inputArray.length; i++) {
                            inputArray[i] *= 2;
                        }
                        return inputArray;
                    }
                
                doubleInPlace() does the same thing as doubleArray() and in the same amount of time, but only takes O(1) space, simply because it doesn’t create a new array. 
                Remember that just because a program has the best runtime possible, doesn’t mean it can’t still be optimized.

5. Nonlinear Data Structures
    > Trees
        Tree data structures are built using tree nodes (a variation on the nodes you created earlier) and are another way of storing information. 
        Specifically, trees are used for data that has a hierarchical structure, such as a family tree or a computer’s file system. 
        The tree data structure you are going to create is an excellent foundation for further variations on trees, including AVL trees, red-black trees, and binary trees.

        Trees Introduction
            Trees are an essential data structure for storing hierarchical data with a directed flow.
            Similar to linked lists and graphs, trees are composed of nodes which hold data. The diagram represents nodes as circles and data as text.
            Nodes also store references to zero or more other tree nodes. Data moves down from node to node. We depict those references as lines drawn between circles.
            Trees are often displayed with a single node at the top and connected nodes branching downwards.
            A company’s organization chart or a computer’s file directory are both real-world examples that can be represented as trees.
        
        Tree Detail
            Trees grow downwards in computer science, and a root node is at the very top. The root of this tree is /photos.
            /photos references to two other nodes: /safari and /wedding. /safari and /wedding are children or child nodes of /photos.
            Conversely, /photos is a parent node because it has child nodes.
            /safari and /wedding share the same parent node, which makes them siblings.
            Note that the /safari node is child (to /photos) and parent (to lion.jpg and giraffe.jpg). It’s extremely common to have nodes act as both parent and child to different nodes within a tree.
            When a node has no children, we refer to it as a leaf node.
            These terms: root, leaf, child, sibling, and parent give us a precise way to communicate the relationships between nodes.
        
        Tree Varietals
            Trees come in various shapes and sizes depending on the dataset modeled.
            - Some are wide, with parent nodes referencing many child nodes.
            - Some are deep, with many parent-child relationships.
            Trees can be both wide and deep, but each node will only ever have at most one parent; otherwise, they wouldn’t be trees!
            Each time we move from a parent to a child, we’re moving down a level. 
            Depending on the orientation we refer to this as the 
                - depth (counting levels down from the root node) or 
                - height (counting levels up from a leaf node).
        
        Binary Search Tree
            Constraints are placed on the data or node arrangement of a tree to solve difficult problems like efficient search.
            A binary tree is a type of tree where each parent can have no more than two children, known as the left child and right child.
            Further constraints make a binary search tree:
                - Left child values must be lesser than their parent.
                - Right child values must be greater than their parent.
            The constraints of a binary search tree allow us to search the tree efficiently. At each node, we can discard half of the remaining possible values!
            Let’s walk through locating the value 31.
                Start at the root: 39
                31 < 39, we move to the left child: 23
                23 < 31, we move to the right child: 35
                31 < 35, we move to the left child: 31
                We found the value 31!
                In a dataset of fifteen elements, we only made three comparisons. What a deal!

        Tree Review
            Trees are useful for modeling data that has a hierarchical relationship which moves in the direction from parent to child. No child node will have more than one parent.
            To recap some terms:
                - root: A node which has no parent. One per tree.
                - parent: A node which references other nodes.
                - child: Nodes referenced by other nodes.
                - sibling: Nodes which have the same parent.
                - leaf: Nodes which have no children.
                - level: The height or depth of the tree. Root nodes are at level 1, their children are at level 2, and so on.

        LEARN TREES: JAVASCRIPT
            Introduction
                Trees are wonderful data structures that can model real life hierarchical information, including organizational charts, genealogical trees, computer file systems, HTML elements on a web page (also known as the Document Object Model, or DOM), state diagrams, and more.
                A tree is composed of tree nodes. A tree node is a very simple data structure that contains:
                    - Data
                    - A list of children, where each child is itself a tree node
                We can add data to and remove data from a tree and traverse it in two different ways:
                    - Depth-first, or
                    - Breadth-first
                In this lesson, we’re going to implement the tree node data structure as a class in JavaScript.
            
                    // TreeNode.js
                    class TreeNode {
                        constructor(data) {
                            this.data = data;
                            this.children = [];             // We will maintain the children of TreeNode as a JavaScript array. This will make it easier to add and remove a child.
                        }
                        addChild(child) {
                            if (child instanceof TreeNode) {
                                this.children.push(child);
                            } else {
                                this.children.push(new TreeNode(child));
                            }
                        }
                        removeChild(childToRemove) {
                            const length = this.children.length;
                            this.children = this.children.filter(child => {
                                if (childToRemove instanceof TreeNode) {
                                    return childToRemove !== child;
                                } else {
                                    return child.data !== childToRemove;
                                }
                            });
                            if (length === this.children.length) {
                                this.children.forEach(child => child.removeChild(childToRemove));
                            }
                        }
                        print(level = 0) {
                            let result = '';
                            for (let i = 0; i < level; i++) {
                                result += '-- ';
                            }
                            console.log(`${result}${this.data}`);
                            this.children.forEach(child => child.print(level + 1));
                        }
                        depthFirstTraversal() {
                            console.log(this.data);
                            this.children.forEach(child => child.depthFirstTraversal());
                        }
                        breadthFirstTraversal() {
                            let queue = [ this ];
                            while (queue.length > 0) {
                                const current = queue.shift();
                                console.log(current.data);
                                queue = queue.concat(current.children);
                            }
                        }
                    };
                    module.exports = TreeNode;

                    // script.js
                    const TreeNode = require('./TreeNode');
                    const tree = new TreeNode(1);       // instantiate your TreeNode class
                    console.log(tree);                  // display your TreeNode class
                    
                    tree.addChild(15);
                    console.log(tree);
                    // const node = new TreeNode(30);
                    // tree.addChild(node);
                    tree.addChild(new TreeNode(30));
                    console.log(tree);

                    tree.removeChild(15);
                    console.log(tree);
                    tree.removeChild(node);
                    console.log(tree);


                    const TreeNode = require('./TreeNode');
                    const tree = new TreeNode(1);
                    const randomize = () => Math.floor(Math.random() * 20);
                    // add first-level children
                    for (let i = 0; i < 3; i++) {
                      tree.addChild(randomize());
                    }
                    // add second-level children
                    for (let i = 0; i < 3; i++) {
                      for (let j = 0; j < 2; j++) {
                        tree.children[i].addChild(randomize());
                      }
                    }
                    // add third-level children
                    for (let i = 0; i < 3; i++) {
                      for (let j = 0; j < 2; j++) {
                        for (let k = 0; k < 2; k++) {
                          tree.children[i].children[j].addChild(randomize());
                        }
                      }
                    }
                    // pretty-print the tree
                    tree.print();
                    tree.depthFirstTraversal();
                    tree.breadthFirstTraversal();

            Adding a Child
                The next task is to add a child to our tree. Each child in our children array has to be an instance of a TreeNode, however we want to allow our user interface to accept adding data in other forms as well.
                For instance, if our method to add a child is .addChild(), we want to accommodate calling tree.addChild(3) as well as tree.addChild(new TreeNode(3)).

            Removing a Child
                Like with .addChild(), we want to provide a flexible interface for removing a child from a tree based on either its data or a TreeNode match.
                The generic steps to execute in removing a child from a tree are as follows:

                    If target child is an instance of TreeNode,
                      Compare target child with each child in the children array
                      Update the children array if target child is found
                    Else 
                      Compare target child with each child's data in the children array
                      Update the children array if target child is found
                    If target child is not found in the children array
                      Recursively call .removeChild() for each grandchild.

                Because we implemented the children as an array, we can use the array .filter() method to update children. Like with .addChild(), we can also use instanceof to check if our target child is an instance of a TreeNode.

            Pretty Print
                Wouldn’t it be nice to be able to display the structure of our tree in a captivating visual way? We have provided a helpful method, .print() that will give you a formatted text display of our tree.
                For example, a tree with 3 levels starting with root node 15, children 3, 12, 0, and grandchildren 6, 9, 19, 8, 10, 19 is displayed below:
                    15
                    -- 3
                    -- -- 6
                    -- -- 9
                    -- 12
                    -- -- 19
                    -- -- 8
                    -- 0
                    -- -- 10
                    -- -- 19
                This method takes one parameter, level, which is initialized to 0, to enable printing the entire tree structure from the top to the bottom.
            
            Depth-first Tree Traversal
                Now that we can add nodes to our tree, the next step is to be able to traverse the tree and display its content. We can do this in one of two ways: depth-first or breadth-first.
                Depth-first traversal visits the first child in the children array and that node’s children recursively before visiting its siblings and their children recursively. The algorithm is as follows:
                    For each node
                        Display its data
                        For each child in children, call itself recursively
                Based on this tree displayed using .print():
                    15
                    -- 3
                    -- -- 6
                    -- -- 9
                    -- 12
                    -- -- 19
                    -- -- 8
                    -- 0
                    -- -- 10
                    -- -- 19
                we can traverse it depth-wise to produce this result:
                    15
                    3
                    6
                    9
                    12
                    19
                    8
                    0
                    10
                    19

            Breadth-first Tree Traversal
                Breadth-first traversal visits each child in the children array starting from the first child before visiting their children and further layers until the bottom level is visited. The algorithm is as follows:
                    Assign an array to contain the current root node
                    While the array is not empty
                        Extract the first tree node from the array
                        Display tree node's data
                        Append tree node's children to the array
                Based on this tree displayed using .print():
                    15
                    -- 3
                    -- -- 6
                    -- -- 9
                    -- 12
                    -- -- 19
                    -- -- 8
                    -- 0
                    -- -- 10
                    -- -- 19
                we can traverse it breadth-wise to produce this result:
                    15
                    3
                    12
                    0
                    6
                    9
                    19
                    8
                    10
                    19
            
            Review
                You have implemented:
                    - TreeNode class that contains data and maintains a collection of TreeNode classes called children.
                    - .addChild() method that adds a child to the tree as either data or TreeNode
                    - .removeChild() method that removes a child from the tree as either data or TreeNode
                    - .depthFirstTraversal() recursive method that fully traverses the tree with a top-down approach for each child of the tree
                    - .breadthFirstTraversal() iterative method that fully traverses the tree a level at a time, instead of a child at a time

            
    > Binary Search and Search Trees
        Binary Search
            When given a sorted array of data, binary search is a way of searching through that data to find an element in O(n log n) time using a divide and conquer approach. It doesn’t require you to look through the entire array in a linear way, which would have a linear big O runtime of O(n).
        Binary Search Trees
            Binary search trees are a type of tree data structure with the added condition that each element to the left of a node must be less than that parent node, and each element to the right of a node must be greater than that parent node. Each left and right subtree is also itself a binary search tree, which makes searching for elements more efficient.
        
        Learn Binary Search
            With a sorted data-set, we can take advantage of the ordering to make a sort which is more efficient than going element by element.
            Let’s say you were looking up the word “Telescope” in the dictionary. You wouldn’t flip through the “A” words and “B” words, page by page, until you got to the page you wanted because you know “T” is near the end of the alphabet.
            You might flip it open near the end and see “R” words. Maybe then you jump ahead and land at “V” words. You would then go slightly backward to find the “T” words.
            At each point, you knew to look forward or backward based on the ordering of the alphabet. We can use this intuition for an algorithm called binary search.
            Binary search requires a sorted data-set. We then take the following steps:
                - Check the middle value of the dataset.
                    - If this value matches our target we can return the index.
                - If the middle value is less than our target
                    - Start at step 1 using the right half of the list.
                - If the middle value is greater than our target
                    - Start at step 1 using the left half of the list.
            We eventually run out of values in the list, or find the target value.
        
        Time Complexity of Binary Search
            How efficient is binary search? 
            In each iteration, we are cutting the list in half. The time complexity is O(log N).
            A sorted list of 64 elements will take at most log2(64) = 6 comparisons.
            In the worst case:
                Comparison 1: We look at the middle of all 64 elements
                Comparison 2: If the middle is not equal to our search value, we would look at 32 elements
                Comparison 3: If the new middle is not equal to our search value, we would look at 16 elements
                Comparison 4: If the new middle is not equal to our search value, we would look at 8 elements
                Comparison 5: If the new middle is not equal to our search value, we would look at 4 elements
                Comparison 6: If the new middle is not equal to our search value, we would look at 2 elements
            When there’s 2 elements, the search value is either one or the other, and thus, there is at most 6 comparisons in a sorted list of size 64.
        
        BINARY SEARCH IN JAVASCRIPT
            Iterative Binary Search
                In this lesson, you will implement an iterative binary search function in JavaScript.
                The function will:
                    - Accept an array of numbers and a value as arguments
                    - Return the index of the value if it is present in the array
                    - Return null if a value is not in the array
                You will test your function by inputting the array shown in the gif to the right as an argument. By the end of this lesson, the following JavaScript code will print 6 to the console.
                    const searchable = [1, 2, 7, 8, 22, 28, 41, 58, 67, 71, 94];
                    const target = 41;
                    console.log(binarySearch(searchable, target)) // 6
                In the code above, also shown visually to the right, we use the binarySearch() function to find the index in searchable that is equal to 41. The index is 6.

            Finding the Middle Index
                A key step in each binary search iteration is to find the middle value of the current list context. In practice, we do this by tracking the first and last indices, then finding their average.
                The first index we check will always be the middle value of the original list. Because of this, we start by setting the following first (left) and last (right) indices. Below, we show a pseudocode example of how to set these variables.
                    function binarySearch (arr, target)
                        left = 0
                        right = length of arr
                        . . .
                We could call a JavaScript implementation of this function with the following code:
                    const searchable = [1, 2, 7, 8, 22, 28, 41, 58, 67, 71, 94];
                    const target = 41;
                    console.log(binarySearch(searchable, target))
                Because we pass in an array of length 11, the right variable is set to 11.
                Next, we calculate the middle index of the array:
                    function binarySearch (arr, target)
                        left = 0
                        right = length of arr

                        indexToCheck = the floor integer of (left + right) / 2
                        . . .
                The above function will calculate the middle index of the array by calculating the average of right and left and rounding it to the floor integer. Given left is zero and right is 11:
                    floor((11 + 0)/2) = 5
                So, the first index the function checks is 5.
                Now you know how to calculate the first indexToCheck. In the next exercise, you will implement an approach to check whether the value at that index is equal to the target.
            
                
                const binarySearch = (arr, target) => {
                    let left = 0;                           // Add left and right variables below
                    let right = arr.length;
                    let indexToCheck = Math.floor((left + right) / 2);      // Add indexToCheck calculation below
                    return indexToCheck;
                }
                const searchable = [1, 2, 7, 8, 22, 28, 41, 58, 67, 71, 94];
                const target = 28;
                console.log(binarySearch(searchable, target));
                module.exports = {binarySearch};
            
            Checking the Middle Index
                Let’s consider how to implement an approach to check whether the value at indexToCheck is equal to the target value. Below, we use pseudocode to display two additional steps that will check if the target value is found.

                    function binarySearch (arr, target)
                        left = 0
                        right = length of arr
                        indexToCheck = the floor integer of (left + right) / 2
                        checking = value of arr at indexToCheck
                        if checking is the target
                            return indexToCheck

                In the example above, we set a variable called checking to the value in arr at the position indexToCheck. Then, we return the index if it is equal to the target value.

                const binarySearch = (arr, target) => {
                  let left = 0;
                  let right = arr.length;
                  const indexToCheck = Math.floor((left + right) / 2);
                  // 1. Create a constant called checking
                  const checking = arr[indexToCheck]
                  // 2. Create a conditional below
                  if (checking === target) {
                    return indexToCheck;
                  }
                  return null;
                }

                const searchable = [1, 2, 7, 8, 22, 28, 41, 58, 67, 71, 94];
                const target = 28;
                console.log(binarySearch(searchable, target));
                module.exports = {binarySearch};

            Iterative Checking
                At this point, you have a function that checks the middle index of an input array and returns the index if the value equals target. Let’s consider how to extend the function to iteratively check sublists when the middle value is not equal to target.
                Remember back to our algorithm, the function continues to execute until the left and right indices converge or the target is found. In practice, we can implement this with the following while condition.

                    while right is greater than left
                        indexToCheck = the floor integer of (left + right) / 2 
                        checking = value of arr at indexToCheck
                        if checking is the target
                            then return indexToCheck

                Unfortunately, the above code will execute infinitely because our right and left variables do not converge from one iteration to the next. To address this issue, in addition to checking if the current value is the target value, we need to adjust the right or left index with each iteration.

                    while right is greater than left
                        indexToCheck = the floor integer of (left + right) / 2 
                        checking = value of arr at indexToCheck
                        if checking is the target
                            then return indexToCheck
                        if target is greater than checking
                            then set left to indexToCheck + 1
                        else
                            set right to indexToCheck

                In the above code, we set the left or right index to a new value based on whether target is greater than or less than checking. The above while loop will continue to execute until the left index is greater than the right index.
                In the checkpoints below, you will add conditions that change the left or right index based on whether checking is greater than or less than target. With each iteration, the distance from left to right will halve.

                    const binarySearch = (arr, target) => {
                      let left = 0;
                      let right = arr.length;

                      while (right > left) {
                        const indexToCheck = Math.floor((left + right) / 2);
                        const checking = arr[indexToCheck];
                        console.log(`indexToCheck equals: ${indexToCheck}`)

                        if (checking === target) {
                          return indexToCheck;
                        } else if (target > checking) {
                          left = indexToCheck + 1;
                        } else {
                          right = indexToCheck;
                        }
                      }
                      return null;
                    }
                    const searchable = [1, 2, 7, 8, 22, 28, 41, 58, 67, 71, 94];
                    const target = 2;
                    const targetIndex = binarySearch(searchable, target);
                    console.log(`The target index is ${targetIndex}.`);
                    module.exports = {binarySearch};

            Review
                In this lesson, you learned how to implement an iterative binary search solution. The function returns the index of the target value from a sorted list. If the target value is not found, the function returns null. You used the following steps to create this function:
                    - Initialize the left and right indices as 0 and the length of the array.
                    - Create a while loop that continues to execute until the left index equals the right index.
                    - Get the value at the index that falls in the middle of left and right.
                    - Return the index if the value is equal to target.
                    - Set left equal to the current index plus one if the target is greater than the value.
                    - Set right equal to the current index minus one if the target is less than the value.
                While the benefits of binary search are significant compared to linear search, it’s important to remember that the function will only work on sorted lists.

        LEARN BINARY SEARCH TREES: JAVASCRIPT
            Introduction
                A binary tree is an efficient data structure for fast data storage and retrieval due to its O(log N) runtime. It is a specialized tree data structure that is made up of a root node, and at most two child branches or subtrees. Each child node is itself a binary tree.
                Each node has the following properties:
                    - data
                    - a depth value, where depth of 1 indicates the top level of the tree and a depth greater than 1 is a level somewhere lower in the tree
                    - a left pointer that points to a left child which is itself a binary tree, and must have a data lesser than the root node’s data
                    - a right pointer that points to a right child which is itself a binary tree, and must have a data greater than the root node’s data
            
                // BinaryTree.js
                class BinaryTree {
                    constructor(value, depth = 1) {
                        this.value = value;
                        this.depth = depth;
                        this.left = null;
                        this.right = null;
                    }
                    insert(value) {
                        if (value < this.value) {
                            if (!this.left) {
                                this.left = new BinaryTree(value, this.depth + 1);
                            } else {
                                this.left.insert(value);
                            }
                        } else {
                            if (!this.right) {
                                this.right = new BinaryTree(value, this.depth + 1);
                            } else {
                                this.right.insert(value);
                            }
                        }
                    }
                    getNodeByValue(value) {
                        if (this.value === value) {
                            return this;
                        } else if ((this.left) && (value < this.value)) {
                            return this.left.getNodeByValue(value);
                        } else if (this.right) {
                            return this.right.getNodeByValue(value);
                        } else {
                            return null;
                        }
                    }
                    depthFirstTraversal() {
                        if (this.left) {
                            this.left.depthFirstTraversal();
                        }
                        console.log(`Depth=${this.depth}, Value=${this.value}`);
                        if (this.right) {
                            this.right.depthFirstTraversal();
                        }
                    }
                };
                module.exports = BinaryTree;

                // script.js
                const BinaryTree = require('./BinaryTree');
                const bt = new BinaryTree(100);          // create a BinaryTree
                // insert values to the BinaryTree here
                bt.insert(50);
                bt.insert(125);
                bt.insert(75);
                bt.insert(25);

                // search for value 75 in BinaryTree
                let node = bt.getNodeByValue(75);
                console.log(node);
                // search for a non-existent value in BinaryTree
                node = bt.getNodeByValue(55);

                console.log(bt);
            
            Inserting a Value
                When inserting a new value into a binary tree, we compare it with the root node’s value:
                    If the new value is less than the root node's value
                        If a left child node doesn't exist 
                            Create a new BinaryTree with the new value at a greater depth and assign it to the left pointer
                        Else
                            Recursively call .insert() on the left child node  
                    Else
                        If a right child node doesn't exist
                            Create a new BinaryTree with the new value at a greater depth and assign it to a right pointer
                        Else
                            Recursively call .insert() on the right child node
            
            Retrieve a Node by Value
                Recall that a binary search tree provides a fast and efficient way to store and retrieve values. Like with .insert(), the procedure to retrieve a tree node by its value is recursive. We want to traverse the correct branch of the tree by comparing the target value to the current node’s value.
                The base case for our recursive method is that when the values match, we return the current node. The recursive step is to call itself from an existing left or right child node with the value.
                    
                    If target value is the same as the current node value
                        Return the current node
                    Else
                        If target value is less than the root node's value and there is a left child node
                            Recursively search from the left child node
                        Else if there is a right child node
                            Recursively search from the right child node

            Traversing a Binary Tree
                There are two main ways of traversing a binary tree: breadth-first and depth-first. With breadth-first traversal, we begin traversing at the top of the tree’s root node, displaying its data and continuing the process with the left child node and the right child node. Descend a level and repeat this step until we finish displaying all the child nodes at the deepest level from left to right.
                With depth-first traversal, we always traverse down each left-side branch of a tree fully before proceeding down the right branch. However, there are three traversal options:
                    - Preorder is when we perform an action on the current node first, followed by its left child node and its right child node
                    - Inorder is when we perform an action on the left child node first, followed by the current node and the right child node
                    - Postorder is when we perform an action on the left child node first, followed by the right child node and then the current node
                For this lesson, we will implement the inorder option. The advantage of this option is that the data is displayed in a sorted order from the smallest to the biggest.
                To illustrate, let’s say we have a binary tree that looks like this:

                           15
                     /------+-----\
                    12            20
                   /   \         /   \   
                 10     13     18     22
                 / \   /  \    / \   /  \
                8  11 12  14  16 19 21  25
                We begin by traversing the left subtree at each level, which brings us to 8, 10 and 11 reside. The inorder traversal would be:
                8, 10, 11
                We ascend one level up to visit root node 12 before we descend back to the bottom where the right subtree of 12, 13, and14` resides. Inorder traversal continues with:
                12, 12, 13, 14
                We again ascend one level up to visit root node 15 before we traverse the right subtree starting at the bottom level again. We continue with the bottom leftmost subtree where 16, 18 and 19 reside. The inorder traversal continues with:
                15, 16, 18, 19
                We ascend one level up to visit root node 20 before we descend back to the bottom where the rightmost subtree of 21, 22 and 25 resides.
                Traversal finishes with:
                20, 21, 22, 25
                The entire traversal becomes:
                8, 10, 11, 12, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 25
                Notice that all the values displayed are sorted in ascending order.

            Review
                In this lesson, you have successfully built a binary tree data structure in JavaScript. You have implemented:
                - BinaryTree class containing value, left and right child nodes and a depth
                - .insert() method to add and place a value at the correct location in the binary tree
                - .getNodeByValue() method to retrieve a child node by its value or null
                - .depthFirstTraversal() method to traverse the binary tree using the inorder traversal option

    > Heaps
        Heaps are another variation of the tree data structure and are adept at keeping track of the maximum or minimum value held within, referred to as max-heaps and min-heaps, respectively. Specifically, heaps are a type of binary tree, since each child node is either greater or less than its parent (depending on if it’s a max-heap or min-heap). They are efficient for accessing the root value, which will either be the max or min (again, depending on the type of heap) and inserting new values.
        Introduction to Heaps
            Heaps are used to maintain a maximum or minimum value in a dataset. Our examples use numbers since this is a straight-forward value, but heaps have many practical applications.
            Imagine you have a demanding boss (hopefully this is theoretical!). They always want the most important thing done. Of course, once you finish the most important task, another one takes its place.
            You can manage this problem using a priority queue to ensure you’re always working on the most pressing assignment and heaps are commonly used to create a priority queue.
            Heaps tracking the maximum or minimum value are max-heaps or min-heaps. We will focus on min-heaps, but the concepts for a max-heap are nearly identical.
            Think of the min-heap as a binary tree with two qualities:
                - The root is the minimum value of the dataset.
                - Every child’s value is greater than its parent.
            These two properties are the defining characteristics of the min-heap. By maintaining these two properties, we can efficiently retrieve and update the minimum value.

        Heap Representations
            We can picture min-heaps as binary trees, where each node has at most two children. As we add elements to the heap, they’re added from left to right until we’ve filled the entire level.
            At the top, we’ve filled the level containing 12 and 20. The next addition comes as the left child of 12, starting a new level in the tree. We would continue filling this level from left to right until 20 had its right child filled.
            Conceptually, the tree representation is beneficial for understanding. Practically, we implement heaps in a sequential data structure like an array or list for efficiency.
            Notice how by filling the tree from left to right; we’re leaving no gaps in the array. The location of each child or parent derives from a formula using the index.
                left child: (index * 2) + 1
                right child: (index * 2) + 2
                parent: (index - 1) / 2 — not used on the root!

        Adding an Element: Heapify Up
            Sometimes you will add an element to the heap that violates the heap’s essential properties.
            We’re adding 3 as a left child of 11, which violates the min-heap property that children must be larger or equal to their parent.
            We need to restore the fundamental heap properties. This restoration is known as heapify or heapifying. We’re adding an element to the bottom of the tree and moving upwards, so we’re heapifying up.
            As long as we’ve violated the heap properties, we’ll swap the offending child with its parent until we restore the properties, or until there’s no parent left. If there is no parent left, that element becomes the new root of the tree.
            3 swaps with 11, but there’s still work to do because now 3 is a child of 5. One more swap and we’ve restored the heap properties. The parent value, 2, is lesser than the child, 3. We can see that 3‘s children 5 and 14 are also greater.
        
        Removing an Element: Heapify Down
            Maintaining a minimum value is no good if we can never retrieve it, so let’s explore how to remove the root node.
            In the diagram, you can see removing the top node itself would be messy: there would be two children orphaned! Instead, we’ll swap the root node, 2, with the bottom rightmost child: 20. The bottom rightmost child is simple to remove because it has no children.
            Unfortunately, we’ve violated the heap property. 20 is now the root node, and that’s not the minimum value in the heap. We’ll heapify down to restore the heap property.
            This process is similar to heapifying up, except we have two options (5 and 10) where we can make a swap. We’ll choose the lesser of the two values and swap 20 with 5. This is necessary for the heap property, if we had chosen to swap 20 with 10, then the minimum value would not be at the root. With 5 at the root, the root node is the minimum value in the heap again.
            Another swap is required because 20 is greater than its children, so we swap 20 with 11.
            Now 20 no longer has any children (it is a child of 11), and all other nodes in the heap only have parents with smaller values.
            Just like that, we’ve retrieved the minimum value, allocated a new minimum, and maintained the heap property!
        
        HEAPS: JAVASCRIPT
            Introduction
                A heap data structure is a specialized tree data structure that satisfies the heap condition:
                    - In a max-heap, for any given element, its parent’s value is greater than or equal to its value.
                    - In a min-heap, for any given element, its parent’s value is less than or equal to its value.
                A heap data structure is commonly implemented as a binary tree. In this lesson, we’re going to implement a min-heap in JavaScript. Min-heaps efficiently keep track of the minimum value in a dataset, even as we add and remove elements.
                Heaps enable solutions for complex problems such as finding the shortest path (Dijkstra’s Algorithm) or efficiently sorting a dataset (heapsort).
                They’re an essential tool for confidently navigating some of the difficult questions posed in a technical interview.
                By understanding the operations of a heap, you will have made a valuable addition to your problem-solving toolkit.
                Example: See /heap_DS
            
            MinHeap Class
                Our MinHeap class will store two pieces of information:
                    - An array of elements within the heap.
                    - A count of the elements within the heap.
                To make our lives easier, we’ll always keep one element at the beginning of the array with the value null. By doing this, we can simplify our coding by always referencing our minimum element at index 1 instead of 0 and our last element at index this.size instead of this.size - 1.
                    const minHeap = new MinHeap();
                    console.log(minHeap.heap);  // [ null ]
                    console.log(minHeap.size);  // 0

            Bubble Up Part I
                Our MinHeap needs to satisfy two conditions:
                    - The element at index 1 is the minimum value in the entire list.
                    - Every child element in the list must be larger than its parent.
                Let’s define an .add() method which will allow us to add elements into the .heap array. We will also define .bubbleUp() which will do the work of maintaining the heap conditions as we add additional elements.

            Parent and Child Elements
                Great work so far! Our MinHeap adds elements to the internal heap, keeps a running count, and has the beginnings of .bubbleUp().
                Before we dive into the logic for .bubbleUp(), let’s review how heaps track elements. We use an array for storing internal elements, but we’re modeling it on a binary tree, where every parent element has up to two child elements.
                Child and parent elements are determined by their relative indices within the internal heap. By doing some arithmetic on an element’s index, we can determine the indices for parent and child elements (if they exist).
                    Parent: (index / 2), rounded down
                    Left Child: index * 2
                    Right Child: (index * 2) + 1
                These calculations are important for the efficiency of the heap, but they’re not necessary to memorize, so we have provided three helper functions: getParent(), getLeft(), and getRight() in MinHeap.js.
                These helpers take an index as the sole parameter and return the corresponding parent or child index.

                    console.log(myHeap.heap) // returns [null, 10, 13, 21, 61, 22, 23, 99]

                    getParent(4); // returns (4 / 2) == 2
                    getLeft(3);   // returns (3 * 2) == 6
                    getRight(3);  // returns (3 * 2) + 1 == 7

            Bubble Up Part II
                Now that we understand how to determine the relationship of elements with the internal heap, we’re ready to finish .bubbleUp().
                In a min-heap, we need to ensure that every child is greater in value than its parent. Let’s add an element to the following heap.

                    console.log(minHeap.heap)   // returns [null, 10, 13, 21, 61, 22, 23, 99]
                    heap.add(12)
                    ( new_element )
                    { parent_element }
                    [null, 10, 13, 21, {61}, 22, 23, 99, (12)]
                    Oh no! We’ve violated the min-heap condition because 12‘s parent, 61, is greater than its child, 12.
                    To fix this, we will exchange the parent and the child elements.

                    before
                        [null, 10, 13, 21, {61}, 22, 23, 99, (12)]
                        SWAP 12 and 61
                    after
                        [null, 10, 13, 21, (12), 22, 23, 99, {61}]
                        12‘s parent is now 13 and it violates the min-heap condition. To fix this, we continue moving upwards swapping parent-child values.

                    before
                        [null, 10, {13}, 21, (12), 22, 23, 99, 61]
                        SWAP 12 and 13
                    after
                        [null, 10, (12), 21, {13}, 22, 23, 99, 61]
                        12‘s parent is now 10 and no longer violates the min-heap condition. We’ve restored the heap!

                    [null, {10}, (12), 21, 13, 22, 23, 99, 61]
                    The child, 12, is greater than the parent, 10!
                    
                    Let’s recap our strategy for .bubbleUp():
                        Set the current element index to be the last index of heap
                            While current element is valid and its value is less than its parent's value
                                Swap the indexes
                                Update the current element index to be its parent index

            Removing the Min
                Min-heaps would be useless if we couldn’t retrieve the minimum value. We’ve gone through a lot of work to maintain that value because we’re going to need it!
                Our goal is to efficiently remove the minimum element from the heap. You’ll recall that we always locate the minimum element at index 1 (a placeholder element occupies index 0).
                Our internal heap mirrors a binary tree. There’s a delicate balance of parent and child relationships we would ruin by directly removing the minimum.

                    console.log(minHeap.heap)   // [null, 10, 21, 13, 61, 22, 23, 99]
                    minHeap.popMin()            // 10
                                                // [null, ???, 21, 13, 61, 22, 23, 99]
                    We need to remove an element that has no children, in this case, the last element. If we swap the minimum with the last element, we can easily remove the minimum from the end of the list.

                    [None, (10), 21, 13, 61, 22, 23, {99}]
                    minHeap.popMin()
                    SWAP minimum with last
                    [None, {99}, 21, 13, 61, 22, 23, (10)]
                    remove minimum
                    [None, 99, 21, 13, 61, 22, 23]
                    10
                    Terrific! We removed the minimum element with minimal disruption. Unfortunately, our heap is out of shape again with 99 sitting where the minimum element should be. We will solve this in exercises to come…

            Heapify I
                We’ve retrieved the minimum element but left our MinHeap in disarray. There’s no reason to get discouraged; we’ve handled this type of problem before, and we can get our MinHeap back in shape!
                We’ll define a method, .heapify(), which performs a similar role to .bubbleUp(), except now we’re moving down the tree instead of up. The current element is a parent that can have either a left child or two children, but not just a right child.
                We have written a helper method, .canSwap(), to return true if swapping can occur for either child and false otherwise:

                canSwap(current, leftChild, rightChild) {   // Check that one of the possible swap conditions exists
                    return (this.exists(leftChild) && this.heap[current] > this.heap[leftChild] 
                            || this.exists(rightChild) && this.heap[current] > this.heap[rightChild]);
                }
                To maintain the min-heap condition, the parent value has to be less than both its child values. To see if a swap is necessary, starting with the left child, we first check that the child exists and then whether the min-heap condition is broken, i.e. the current element has a value greater than that child’s value. If the left child does not break the min-heap condition, the same check is performed on the right child.

            Heapify II
                In .bubbleUp(), we were always comparing our element with its parent. In .heapify(), we have potentially two options: the left child and the right child.
                Which should we choose? We’ll use an example to think it through. Imagine we have a heap with four elements:

                console.log(minHeap.heap)   // [null, 21, 36, 58, 42]
                minHeap.popMin()            // 21
                // [null, 42, 36, 58]
                // Should we swap 42 with 36 or 58?
                We want to swap with the smaller of the two children, otherwise, we wouldn’t maintain our heap condition!
            
                //MinHeap.js
                class MinHeap {
                    constructor() {
                        this.heap = [ null ];
                        this.size = 0;
                    }

                    popMin() {
                        if (this.size === 0) {
                        return null
                        }
                        console.log(`\n.. Swap ${this.heap[1]} with last element ${this.heap[this.size]}`);
                        this.swap(1, this.size);
                        const min = this.heap.pop();
                        this.size--;
                        console.log(`.. Removed ${min} from heap`);
                        console.log('..',this.heap);
                        this.heapify();     // Heapify I
                        return min;
                    }

                    add(value) {
                        console.log(`.. adding ${value}`);
                        this.heap.push(value);
                        this.size++;
                        this.bubbleUp();
                        console.log(`added ${value} to heap`, this.heap);
                    }

                    bubbleUp() {
                        let current = this.size;
                        while (current > 1 && this.heap[getParent(current)] > this.heap[current]) {
                        console.log(`.. swap ${this.heap[current]} with parent ${this.heap[getParent(current)]}`);
                        this.swap(current, getParent(current));
                        console.log('..', this.heap);
                        current = getParent(current);
                        }
                    }

                    heapify() {                                 // Removing the Min
                        let current = 1;
                        let leftChild = getLeft(current);
                        let rightChild = getRight(current);

                        while (this.canSwap(current, leftChild, rightChild)) {
                            while (this.canSwap(current, leftChild, rightChild)) {      // Heapify I
                                if (this.exists(leftChild) && this.exists(rightChild)) {
                                    if (this.heap[leftChild] < this.heap[rightChild]) {
                                        this.swap(current, leftChild);
                                        current = leftChild;
                                    } else {
                                        this.swap(current, rightChild);
                                        current = rightChild;
                                    }        
                                } else {
                                    this.swap(current, leftChild);
                                    current = leftChild;
                                }
                                leftChild = getLeft(current);
                                rightChild = getRight(current);
                            }
                            leftChild = getLeft(current);
                            rightChild = getRight(current);
                        }
                    }

                    exists(index) {
                        return index <= this.size;
                    }

                    canSwap(current, leftChild, rightChild) {
                        // Check that one of the possible swap conditions exists
                        return (
                        this.exists(leftChild) && this.heap[current] > this.heap[leftChild]
                        || this.exists(rightChild) && this.heap[current] > this.heap[rightChild]
                        );
                    }

                    swap(a, b) {
                        [this.heap[a], this.heap[b]] = [this.heap[b], this.heap[a]];
                    }
                }

                const getParent = current => Math.floor((current / 2));
                const getLeft = current => current * 2;
                const getRight = current => current * 2 + 1;

                module.exports = MinHeap;

                // script.js

                // import MinHeap class
                const MinHeap = require('./MinHeap');

                // instantiate a MinHeap class
                const minHeap = new MinHeap();

                // helper function to return a random integer
                function randomize() { return Math.floor(Math.random() * 40); }

                // populate minHeap with random numbers
                for (let i=0; i < 6; i++) {
                  minHeap.add(randomize());
                }

                // display the bubbled up numbers in the heap
                console.log('Bubbled Up', minHeap.heap);

                // remove the minimum value from heap
                for (let i=0; i < 6; i++) {
                  minHeap.popMin();
                  console.log('Heapified', minHeap.heap);
                }
            
            Review
                Nice work! You’ve implemented a min-heap in JavaScript, and that’s no small feat (although it could efficiently track the smallest feat).
                To recap: MinHeap tracks the minimum element as the element at index 1 within an internal Javascript array.
                When adding elements, we use .bubbleUp() to compare the new element with its parent, making swaps if it violates the heap condition: children must be greater than their parents.
                When removing the minimum element, we swap it with the last element in the heap. Then we use .heapify() to compare the new root with its children, swapping with the smaller child if necessary.
                Heaps are useful because they’re efficient in maintaining their heap condition. Building a heap using elements that decrease in value would ensure that we continually violate the heap condition. How many swaps would that cause?

6. Sorting Algorithms
    Binary search was efficient when given a pre-sorted data set, but what are the most efficient ways to actually sort data sets? 
    There are many different sorting algorithms, but you are going to focus on three of the most common: bubble sort, merge sort, and quicksort. 
    Each has pros and cons when it comes to their efficiency. 

    > Bubble Sort
            Bubble Sort Introduction
                Bubble sort is an introductory sorting algorithm that iterates through a list and compares pairings of adjacent elements.
                According to the sorting criteria, the algorithm swaps elements to shift elements towards the beginning or end of the list.
                By default, a list is sorted if for any element e and position 1 through N:
                    e1 <= e2 <= e3 … eN, where N is the number of elements in the list.
                    For example, bubble sort transforms a list:     [5, 2, 9, 1, 5]
                    to an ascending order, from lowest to highest:  [1, 2, 5, 5, 9]

                We implement the algorithm with two loops.
                    The first loop iterates as long as the list is unsorted and we assume it’s unsorted to start.
                    Within this loop, another iteration moves through the list. For each pairing, the algorithm asks:
                    In comparison, is the first element larger than the second element?
                    If it is, we swap the position of the elements. The larger element is now at a greater index than the smaller element.
                    When a swap is made, we know the list is still unsorted. The outer loop will run again when the inner loop concludes.
                    The process repeats until the largest element makes its way to the last index of the list. The outer loop runs until no swaps are made within the inner loop.
            
            Bubble Sort
                As mentioned, the bubble sort algorithm swaps elements if the element on the left is larger than the one on the right.
                How does this algorithm swap these elements in practice?
                    Let’s say we have the two values stored at the following indices index_1 and index_2. How would we swap these two elements within the list?
                    It is tempting to write code like:
                    list[index_1] = list[index_2]
                    list[index_2] = list[index_1]
                    However, if we do this, we lose the original value at index_1. The element gets replaced by the value at index_2. Both indices end up with the value at index_2.
                    Programming languages have different ways of avoiding this issue. In some languages, we create a temporary variable which holds one element during the swap:
                    temp = list[index_1]
                    list[index_1] = list[index_2]
                    list[index_2] = temp 
                    Other languages provide multiple assignment which removes the need for a temporary variable.
                    list[index_1], list[index_2] = list[index_2], list[index_1]
            
            Algorithm Analysis
                Given a moderately unsorted data-set, bubble sort requires multiple passes through the input before producing a sorted list. Each pass through the list will place the next largest value in its proper place.
                    We are performing n-1 comparisons for our inner loop. Then, we must go through the list n times in order to ensure that each item in our list has been placed in its proper order.
                    The n signifies the number of elements in the list. In a worst case scenario, the inner loop does n-1 comparisons for each n element in the list.
                    Therefore we calculate the algorithm’s efficiency as:
                        O(n(n−1))=O(n(n))=O(n^2)
                    When calculating the run-time efficiency of an algorithm, we drop the constant (-1), which simplifies our inner loop comparisons to n.
                    This is how we arrive at the algorithm’s runtime: O(n^2).

            Bubble Sort Review
            - Bubble sort is an algorithm to sort a list through repeated swaps of adjacent elements. It has a runtime of O(n^2).
            - For nearly sorted lists, bubble sort performs relatively few operations since it only performs a swap when elements are out of order.
            - Bubble sort is a good introductory algorithm which opens the door to learning more complex algorithms. It answers the question, “How can we algorithmically sort a list?” and encourages us to ask, “How can we improve this sorting algorithm?”

            BUBBLE SORT: JAVASCRIPT
            Intro to Bubble Sort
                The bubble sort algorithm takes an array of elements and reorders the elements of the input from smallest to largest. 
                To achieve this, bubble sort works by comparing a pair of neighboring elements and swapping their positions in the array so that the larger of the two elements is always on the right. 
                Doing this continuously results in the largest element “bubbling” up to the end of the array, giving this sort its name. 
                The algorithm only stops when there are no more values that need to be swapped.

                Pseudocode:
                    while array is not sorted
                        for each value in array
                            if current value > next value
                                swap current value and next value
                    return array 

                Bubble sort is not the most efficient sorting algorithm. 
                Bubble sort’s worst-case runtime is O(n^2). This is because we have to compare the current element we are looking at, to each element in the array after it and repeat this check for every single element in the array. 
                Its best-case runtime is O(n) for an already-sorted list.
                
            Loops
                In order to sort an array, we’ll need to visit pairs of elements and check if they should be moved or kept at their current index. To accomplish this we’ll use two loops:

                One loop that will execute an inner loop depending on the state of a variable representing whether the input array might be sorted or not
                An inner loop to compare and swap pairs of elements in the array

                // bubbleSort.js
                const swap = require('./swap');

                const bubbleSort = input => {
                    let swapCount = 0
                    let swapping = true;

                    while (swapping) {
                        swapping = false;
                        for (let i = 0; i < input.length - 1; i++) {
                            if (input[i] > input[i + 1]) {
                                swap(input, i, i + 1)
                                swapCount++;
                                swapping = true;
                            }
                        }
                    }
                    return input;
                };
                module.exports = bubbleSort;

                // Reverse-sorted array:
                bubbleSort([9, 8, 7, 6, 5, 4, 3, 2, 1]);
                // Sorted array:
                bubbleSort([1, 2, 3, 4, 5, 6, 7, 8, 9]);

                // swap.js
                const swap = (arr, indexOne, indexTwo) => {
                    const temp = arr[indexTwo];
                    arr[indexTwo] = arr[indexOne];
                    arr[indexOne] = temp;
                };
                module.exports = swap;

    > Merge Sort
            MERGE SORT: CONCEPTUAL
            What Is A Merge Sort?
                Merge sort is a sorting algorithm created by John von Neumann in 1945. 
                Merge sort’s “killer app” was the strategy that breaks the list-to-be-sorted into smaller parts, sometimes called a divide-and-conquer algorithm.
                In a divide-and-conquer algorithm, the data is continually broken down into smaller elements until sorting them becomes really simple.
                Merge sort was the first of many sorts that use this strategy, and is still in use today in many different applications.

            How To Merge Sort:
                Merge sorting takes two steps: 
                    - splitting the data into “runs” or smaller components.
                        When splitting the data, we divide the input to our sort in half. We then recursively call the sort on each of those halves, which cuts the halves into quarters. This process continues until all of the lists contain only a single element. Then we begin merging.
                    - re-combining those runs into sorted lists (the “merge”).
                        When merging two single-element lists, we check if the first element is smaller or larger than the other. Then we return the two-element list with the smaller element followed by the larger element.
            
            Merging
                When merging larger pre-sorted lists, we build the list similarly to how we did with single-element lists.
                Let’s call the two lists left and right. Both left and right are already sorted. We want to combine them (to merge them) into a larger sorted list, let’s call it both. To accomplish this we’ll need to iterate through both with two indices, left_index and right_index.
                At first left_index and right_index both point to the start of their respective lists. left_index points to the smallest element of left (its first element) and right_index points to the smallest element of right.
                Compare the elements at left_index and right_index. The smaller of these two elements should be the first element of both because it’s the smallest of both! It’s the smallest of the two smallest values.
                Let’s say that smallest value was in left. We continue by incrementing left_index to point to the next-smallest value in left. Then we compare the 2nd smallest value in left against the smallest value of right. Whichever is smaller of these two is now the 2nd smallest value of both.
                This process of “look at the two next-smallest elements of each list and add the smaller one to our resulting list” continues on for as long as both lists have elements to compare. Once one list is exhausted, say every element from left has been added to the result, then we know that all the elements of the other list, right, should go at the end of the resulting list (they’re larger than every element we’ve added so far).
            
            Merge Sort Performance
                Merge sort was unique for its time in that the best, worst, and average time complexity are all the same: Θ(N*log(N)). This means an almost-sorted list will take the same amount of time as a completely out-of-order list. This is acceptable because the worst-case scenario, where a sort could stand to take the most time, is as fast as a sorting algorithm can be.
                Some sorts attempt to improve upon the merge sort by first inspecting the input and looking for “runs” that are already pre-sorted. Timsort is one such algorithm that attempts to use pre-sorted data in a list to the sorting algorithm’s advantage. If the data is already sorted, Timsort runs in Θ(N) time.
                Merge sort also requires space. Each separation requires a temporary array, and so a merge sort would require enough space to save the whole of the input a second time. This means the worst-case space complexity of merge sort is O(N).

            MERGE SORT: JAVASCRIPT
            Introduction
                The algorithm consists of two distinct steps:
                    Splitting the input array – The algorithm recursively splits the input array until each element is in its own array.
                    Merging sorted arrays – The algorithm compares and combines the elements of arrays until the input array is sorted. 
            
            Splitting: Base Case
                In this implementation of merge sort, you will build a recursive function, called mergeSort(), that splits the input array until each element is in its own array.
                So, if the input array is: [3, 5, 2]
                splitting these elements into their own arrays will look like: [3] [5] [2]
                The base case of this recursive function is when the input array has only one element in it. 

                Pseudocode:
                    function mergeSort(arr)
                        if the length of arr equals 1
                            return arr
                        
                        midIndex = the floor integer of (left + right) / 2
                        leftArr = arr from 0 to midIndex
                        rightArr = arr from midIndex to end

                        // mergeSort(leftArray)
                        // mergeSort(rightArray)   // This is our recursive call.

                        return merge(mergeSort(leftArray), mergeSort(rightArray))

                // index.js
                const mergeSort = (startArray) => {
                    const length = startArray.length;
                    if (length === 1) {
                        return startArray;
                    }
                    
                    const mid = Math.floor(length / 2);
                    const leftArray = startArray.slice(0, mid);
                    const rightArray = startArray.slice(mid, length);
                    
                    // mergeSort(leftArray);
                    // mergeSort(rightArray);
                    return merge(mergeSort(leftArray), mergeSort(rightArray));
                }
                const merge = (leftArray, rightArray) => {
                    const sortedArray = [];
                    while (leftArray.length > 0 && rightArray.length > 0) {
                        if (leftArray[0] < rightArray[0]) {
                            sortedArray.push(leftArray[0]);
                            leftArray.shift();
                        } else {
                            sortedArray.push(rightArray[0]);
                            rightArray.shift();
                        }
                    }
                    return sortedArray.concat(leftArray).concat(rightArray);
                }

                const inputArr = [3, 5, 2, 90, 4, 7];
                console.log(mergeSort(inputArr));

                module.exports = {
                    mergeSort
                };

            Review
            - Algorithm is broken into two parts: splitting and merging.
            - Regardless of the order or length (including odd or even lengths) of an input array, the merge sort algorithm will always split the elements into their own arrays first, and then combine them into a sorted array. The fact that the same steps are taken regardless of the input (order and length) results in an average, best, and worst case complexity all equal to the same value, O(n log n).
            - This time complexity makes merge sort one of the most efficient and popular sorting algorithms. 

    > Quicksort 
            QUICKSORT: CONCEPTUAL
            Introduction to Quicksort
                Quicksort is an efficient recursive algorithm for sorting arrays or lists of values. The algorithm is a comparison sort, where values are ordered by a comparison operation such as > or <.
                Quicksort uses a divide and conquer strategy, breaking the problem into smaller sub-problems until the solution is so clear there’s nothing to solve.
                We choose a single pivot element from the list. Every other element is compared with the pivot, which partitions the array into three groups.
                    - A sub-array of elements smaller than the pivot.
                    - The pivot itself.
                    - A sub-array of elements greater than the pivot.
                The process is repeated on the sub-arrays until they contain zero or one element. Elements in the “smaller than” group are never compared with elements in the “greater than” group. If the smaller and greater groupings are roughly equal, this cuts the problem in half with each partition step!
                    [6,5,2,1,9,3,8,7]
                        6 # The pivot
                        [5, 2, 1, 3] # lesser than 6    # these values will never be compared with [9,8,7]
                        [9, 8, 7] # greater than 6
    
                Depending on the implementation, the sub-arrays of one element each are recombined into a new array with sorted ordering, or values within the original array are swapped in-place, producing a sorted mutation of the original array.

            Quicksort Runtime
                The key to Quicksort’s runtime efficiency is the division of the array. The array is partitioned according to comparisons with the pivot element, so which pivot is the optimal choice to produce sub-arrays of roughly equal length?
                The graphic displays two data sets which always use the first element as the pivot. Notice how many more steps are required when the quicksort algorithm is run on an already sorted input. The partition step of the algorithm hardly divides the array at all!
                The worst case occurs when we have an imbalanced partition like when the first element is continually chosen in a sorted data-set.
                One popular strategy is to select a random element as the pivot for each step. The benefit is that no particular data set can be chosen ahead of time to make the algorithm perform poorly.
                Another popular strategy is to take the first, middle, and last elements of the array and choose the median element as the pivot. The benefit is that the division of the array tends to be more uniform.
                
                Quicksort is an unusual algorithm in that the worst case runtime is O(N^2), but the average case is O(N * logN).
                We typically only discuss the worst case when talking about an algorithm’s runtime, but for Quicksort it’s so uncommon that we generally refer to it as O(N * logN).
                
            Quicksort Review
                - Quicksort is an efficient algorithm for sorting values in a list. A single element, the pivot, is chosen from the list. All the remaining values are partitioned into two sub-lists containing the values smaller than and greater than the pivot element.
                - Ideally, this process of dividing the array will produce sub-lists of nearly equal length, otherwise, the runtime of the algorithm suffers.
                - When the dividing step returns sub-lists that have one or less elements, each sub-list is sorted. The sub-lists are recombined, or swaps are made in the original array, to produce a sorted list of values.

            QUICKSORT: JAVASCRIPT
            Introduction
                Quicksort is an efficient sorting algorithm that is based on the divide and conquer strategy. 
                    Like merge sort, the input array is partitioned into smaller parts and then combined after the elements have been rearranged. 
                    Unlike merge sort, which requires additional memory for auxiliary arrays, quicksort is space-saving because it deploys in-place sorting.

                As runtime performance goes, quicksort requires more comparisons for sorting a larger input than mergesort. Like bubble sort, quicksort has a worst case runtime of O(N^2). This can happen when quicksort’s input data set comprises:
                    - pre-sorted numbers,
                    - backward-sorted numbers, or
                    - all similar elements along with a poorly chosen pivot element that produces a partition of zero or one element.
                On average, like merge sort, the runtime of quicksort is O(N * log N) if partition sizes are roughly equal.

                The basic idea of the quicksort algorithm is to:
                    - split the initial unsorted data set into a left partition and a right partition
                    - sort each partition recursively until there is only one element left
                    - return the sorted array
                We use a pivot element to divide our unsorted array into two parts. The elements in these parts must meet these conditions after partitioning:
                    - all elements in the left partition must be less than or equal to the pivot element
                    - all elements in the right partition must be greater than or equal to the pivot element
                Determining the pivot index is done through a procedure called partitioning. Our algorithm uses an array to store the data set and stipulates the boundary of the data set with left and right pointers.
                
                Pseudocode:
                    If there is more than one element left in the array:
                        Find the pivot index through partitioning
                    If the left pointer is less than the pivot index:
                        Call quicksort() on the portion of the array between the left pointer and the pivot. 
                    If the pivot index is less than the right pointer:
                        Call quicksort() on the portion of the array between the pivot index and the right pointer.
                    Return the sorted array
                

                // script.js
                const { quicksort, partition } = require('./quicksort');

                const randomize = () => Math.floor(Math.random() * 40);

                let numbers = [];

                for (let i = 0; i < 5; i++) {
                    numbers.push(randomize());
                }

                console.log('Before quicksort:', numbers);
                const sorted = quicksort(numbers);
                console.log('After  quicksort:', sorted);

                // quicksort.js
                const swap = require('./swap');

                const quicksort = (array, leftBound = 0, rightBound = array.length - 1) => {
                    if (leftBound < rightBound) {
                        const pivotIndex = partition(array, leftBound, rightBound);
                        quicksort(array, leftBound, pivotIndex - 1);
                        quicksort(array, pivotIndex, rightBound);
                    }
                    return array;
                }

                const partition = (array, leftIndex, rightIndex) => {
                    const pivot = array[Math.floor((rightIndex + leftIndex) / 2)];
                    while (leftIndex <= rightIndex) {
                        while (array[leftIndex] < pivot) {
                        leftIndex++;
                        }
                        while (array[rightIndex] > pivot) {
                        rightIndex--;
                        }
                        if (leftIndex <= rightIndex) {
                        swap(array, leftIndex, rightIndex);
                        leftIndex++;
                        rightIndex--;
                        }
                    }
                    return leftIndex;
                }

                module.exports = {
                    quicksort, 
                    partition, 
                };

                //swap.js
                const swap = (arr, indexOne, indexTwo) => {
                    const temp = arr[indexTwo];
                    arr[indexTwo] = arr[indexOne];
                    arr[indexOne] = temp;
                }

                module.exports = swap;

            Partitioning Part I - The Pivot Element
                Partitioning is the crux of the quicksort algorithm. Without it, we wouldn’t know how to split our unsorted array into useful partitions.
                This procedure utilizes two internal indices, leftIndex and rightIndex that move in opposite directions. 
                These indices are used for:
                    - computing the pivot element
                    - comparing the elements located at each index with the pivot element
                    - determining the pivot index, the desired location of the pivot element in the set after elements have been swapped, if any
                The basic idea of partitioning is as follows:
                    - Start with the middle element
                    - While you haven’t looked through the whole array (leftIndex is still < rightIndex)
                    - move leftIndex up until you find something greater than the pivot
                    - move rightIndex down until you find something less than the pivot
                    - swap those elements, and move the indices in by one step so to continue checking if swaps are necessary
                    - return the last left element index
                An initial pivot element can be arbitrarily chosen in the beginning of the partitioning process to be one of the following by default:
                    - first element of the array
                    - last element of the array
                    - middle element of the array
                    - random element of the array
                The final location of the pivot element will be determined at the end of the partitioning process.

                In some quicksort implementations, the first or last element is commonly picked as the pivot element. 
                In our JavaScript implementation, we will use the middle element instead because it provides a better average runtime. 
                To do this, we will need both leftIndex and rightIndex.
                    pivot = the average of the sum of leftIndex and rightIndex rounded down 

            Partitioning Part II - The Left and Right Indices
                The leftIndex and rightIndex of a set or subset are going to set the bounds of the partition. 
                For the first iteration, both indices mark the entire span of the original data set. 
                In the following illustrations, L and R represent leftIndex and rightIndex respectively.
                    [ 3, 1, 4, 2, 8, 9 ]
                    L     P        R
                The pivot element for this set will be 4 as it is located near the halfpoint of the data set and indicated by P.
                Next, we want to compare the element at leftIndex with the pivot element, 4. As long as it is less than the pivot, meaning that it is in the correct half of the partition, we want to move the leftIndex forward one step to the right.
                    3 < 4, move L forward
                    [ 3, 1, 4, 2, 8, 9 ]
                        L  P        R
                    1 < 4, move L forward
                    [ 3, 1, 4, 2, 8, 9 ]
                            L        R
                            P
                    4 = 4, stop
                We stop leftIndex at position 2 because the element at index 2 (4) is not less than the pivot element 4. Next, we switch focus to the rightIndex and compare the element at rightIndex with the pivot element, 4. As long as it is greater than the pivot, we want to move the rightIndex backward one step to the left.
                    [ 3, 1, 4, 2, 8, 9 ]
                            L        R
                            P
                    9 > 4, move R backward
                    [ 3, 1, 4, 2, 8, 9 ]
                            L     R
                            P
                    8 > 4, move R backward
                    [ 3, 1, 4, 2, 8, 9 ]
                            L  R
                            P
                    2 < 4, stop
                We stop the rightIndex at position 3 because the element at 3 (2) is not greater than the pivot element 4. This tells us that 2 does not belong in its current position because it should be on the left of the pivot element 4. In this case, we need to swap the elements at leftIndex and rightIndex.
                We will handle swapping of index elements in the next exercise.

            Partitioning Part III - Swapping
                Recall that our leftIndex and rightIndex were at 2 and 3 respectively. 
                They cannot move any further because their respective elements are greater than or less than the pivot element. When this happens, we need to swap those elements so that they will end up at the correct side of the partition.
                    [ 3, 1, 4, 2, 8, 9 ]
                            L  R
                            P
                    swap 4 and 2
                    [ 3, 1, 2, 4, 8, 9 ]
                            L  R
                            P
                After we swap them, we move L forward and R backward.
                Move L forward and R backward
                    [ 3, 1, 2, 4, 8, 9 ]
                            R  L
                            P
                We return to our outer while loop condition to check if leftIndex (3) is less than or equal to rightIndex (2). In this case, 3 > 2, so we exit the while loop.

                At this juncture, the elements that are less than the pivot are to the left of it and the elements that are greater than the pivot are to the right of it. 
                We can stop partitioning and return the leftIndex which points to the pivot element 4. 
                Hence, our pivot index is 3 which is also the leftIndex.

            Recursive Quicksort
                Now that we have finished implementing partition(), let’s implement the quicksort() function, which is recursive. 
                This function takes in three parameters:
                    - Input array
                    - Left pointer
                    - Right pointer
                The base case for this function is when the array has one element, meaning that it is sorted. As a result, the array is returned. Our JavaScript implementation does in-place sorting, hence, the array size does not change. A one-element array is symbolized by both left and right pointers pointing to the same element.
                Our quicksort() function will start by calling the partition() function with the input array bounded by the left and right pointers as long as the left pointer is less than the right pointer.
                The recursive steps are executed after partitioning:
                    Call quicksort() to process only the left partition bounded by the left pointer and (pivot index - 1) to exclude the pivot element from the left partition
                    Call quicksort() to process only the right partition bounded by the pivot index and right pointer
                    Continuing from the example in the last exercise, recall that we returned a pivot index, P, that points to pivot element 4 at index 3 as pointed to by L.
                    [ 3, 1, 2, 4, 8, 9 ]
                            R  L
                            P
                Recall that the initial left pointer, which we will call leftBound is 0 and the initial right pointer, rightBound, is 4.
                Recursively call quicksort() with the array [ 3, 1, 2, 4, 8, 9 ], left pointer 0 and right pointer 2 for the left partition [ 3, 1, 2 ] which excludes the pivot index, 3.
                Similarly, we will recursively call quicksort() with the array [ 3, 1, 2, 4, 8, 9 ], left pointer 3 and right pointer 5 for the right partition [ 4, 8, 9 ] which includes the pivot index, 3.

            Logging
                Let’s put our implementation of the quicksort algorithm into practice. 
                In order to understand what is going on internally inside each call to quicksort() and partition(), we have inserted log statements at various steps to illustrate the following events:
                    - a recursive call is about to occur
                    - partitioning is taking place
                    - leftIndex and rightIndex are incremented
                    - swapping has taken place

            
            Review
                - Quicksort is a divide-and-conquer algorithm that splits an unsorted data set into two partitions recursively and sorts the partitioned arrays in-place until there is only one element left in a partition.
                - To determine the elements that belong in a partition, we need a pivot element, pivot, that is sandwiched between the two partitions and its location called the pivotIndex.
                - We implemented the partition() function which groups and swaps the elements either to the left or right of the pivot element and returns the leftIndex that is the same as the pivotIndex.
                - We implemented the quicksort() function that first calls partition() to determine the pivotIndex then recursively calls itself to sort the smaller partitions until there is only one element left in the partition.

7. Graph Data Structures
    > Graphs
        Graphs are used to represent data points, or vertices, that are connected by edges. 
        Common applications for graphs are things like maps, where each location is a vertex, and each path, or road, between the locations is an edge. 
        Graphs can be directed (a one-way street) or undirected (a two-way street), as well as weighted or unweighted (think of the length of each street as a potential measurement of weight).

        GRAPHS: CONCEPTUAL
        Introduction to Graphs
            Graphs are the perfect DS for modeling networks, which make them an indispensable piece of your DS toolkit. 
            They’re composed of 
            - nodes, or vertices, which hold data, and 
            - edges, which are a connection between two vertices. A single node is a vertex.

            Consider a map of the area where you live. As a graph, we could model bus stops as vertices, with bus routes between stops functioning as the edges.
            What about the internet? Web pages can be vertices, and the hyperlinks which connect them are edges.
            Real-world relationships modeled as graphs are numerous, making them an essential concept to master.
        
        Directed Graphs
        Representing Graphs
            We typically represent the vertex-edge relationship of a graph in two ways: an adjacency list or an adjacency matrix.
            An adjacency matrix is a table. Across the top, every vertex in the graph appears as a column. Down the side, every vertex appears again as a row. Edges can be bi-directional, so each vertex is listed twice.
            To find an edge between B and P, we would look for the B row and then trace across to the P column. The contents of this cell represent a possible edge.
            Our diagram uses 1 to mark an edge, 0 for the absence of an edge. In a weighted graph, the cell contains the cost of that edge.
            In an adjacency list, each vertex contains a list of the vertices where an edge exists. To find an edge, one looks through the list for the desired vertex.

        Reviewing Key Terms
            Graphs are an essential DS in computer science for modeling networks. 
            - vertex: A node in a graph.
            - edge: A connection between two vertices.
            - adjacent: When an edge exists between vertices.
            - path: A sequence of one or more edges between vertices.
            - disconnected: Graph where at least two vertices have no path connecting them.
            - weighted: Graph where edges have an associated cost.
            - directed: Graph where travel between vertices can be restricted to a single direction.
            - cycle: A path which begins and ends at the same vertex.
            - adjacency matrix: Graph representation where vertices are both the rows and the columns. Each cell represents a possible edge.
            - adjacency list: Graph representation where each vertex has a list of all the vertices it shares an edge with.
        
        GRAPHS: JAVASCRIPT
        Introduction to Graphs
            In this lesson, we’ll take an object-oriented approach to build an implementation of the graph DS in JavaScript. 
            With three classes, Edge, Vertex, and Graph, we can implement a variety of graphs that satisfy the requirements of many algorithms. 
            Remember that a Graph consists of vertices and their corresponding edges.

            For this lesson, we want our Graph class to be flexible enough to support directed, undirected, weighted, and unweighted graphs. 
            We will provide you with an Edge class that connects two vertices, along with the weight of the connection (to support weighted graphs).

            With this in mind, we will create our Graph with the following requirements:
                - A Vertex can store any data.
                - A Vertex maintains a list of connections to other vertices, represented by a list of Edge instances.
                - A Vertex can add and remove edges going to another Vertex.
                - A Graph stores all of its vertices, represented by a list of Vertex instances.
                - A Graph knows if it is directed or undirected.
                - A Graph knows if it is weighted or unweighted.
                - A Graph can add and remove its own vertices.
                - A Graph can add and remove edges between stored vertices.

            Let’s start with familiarizing ourselves with the classes that we will build in Vertex.js and Graph.js. 
            We already set up .print() methods for you that will print out the state of the graph structure. 
            Don’t worry about the class in Edge.js yet. We will use it to connect the vertices in a later exercise.

            To keep the concepts grounded in a real-world application, we’ll build a transportation network of railroads and train stations as we go.


            // Vertex.js
            const Edge = require('./Edge.js');

            class Vertex {
                constructor(data) {
                    this.data = data;
                    this.edges = [];
                }

                addEdge(vertex, weight) {               // Connecting Vertices with Edges
                    if (vertex instanceof Vertex) {
                        this.edges.push(new Edge(this, vertex, weight));
                    } else {
                        throw new Error('Edge start and end must both be Vertex');
                    }
                }
                removeEdge(vertex) {                // Removing Vertex Connections
                    this.edges = this.edges.filter(edge => edge.end !== vertex);
                }

                print() {
                    const edgeList = this.edges.map(edge =>
                        edge.weight !== null ? `${edge.end.data} (${edge.weight})` : edge.end.data) || [];

                    const output = `${this.data} --> ${edgeList.join(', ')}`;
                    console.log(output);
                }
            }

            module.exports = Vertex;

            //Graph.js
            const Edge = require('./Edge.js');
            const Vertex = require('./Vertex.js');

            class Graph {
                constructor(isWeighted = false, isDirected = false) {
                    this.vertices = [];
                    this.isWeighted = isWeighted;       // Weighted Graphs
                    this.isDirected = isDirected;       // Directed Graphs
                }

                addVertex(data) {                               // Adding Vertices
                    const newVertex = new Vertex(data);
                    this.vertices.push(newVertex);

                    return newVertex;
                }

                removeVertex(vertex) {                          // Removing Vertices
                    this.vertices = this.vertices.filter(v => v !== vertex);
                }

                addEdge(vertexOne, vertexTwo, weight) {         // Connecting Vertices with Edges
                    const edgeWeight = this.isWeighted ? weight : null;     // Weighted Graphs

                    if (vertexOne instanceof Vertex && vertexTwo instanceof Vertex) {
                        vertexOne.addEdge(vertexTwo, edgeWeight);
                        if (!this.isDirected) {                 // Directed Graphs
                            vertexTwo.addEdge(vertexOne, edgeWeight);
                        }
                    } else {
                        throw new Error('Expected Vertex arguments.');
                    }
                }

                removeEdge(vertexOne, vertexTwo) {
                    if (vertexOne instanceof Vertex && vertexTwo instanceof Vertex) {
                        vertexOne.removeEdge(vertexTwo);
                        if (!this.isDirected) {                 // Directed Graphs
                            vertexTwo.removeEdge(vertexOne);
                        }
                    } else {
                        throw new Error('Expected Vertex arguments.');
                    }
                }

                print() {
                    const vertexList = this.vertices || [];
                    vertexList.forEach(vertex => vertex.print());
                }
            }

            const trainNetwork = new Graph();
            const atlantaStation = trainNetwork.addVertex('Atlanta');
            const newYorkStation = trainNetwork.addVertex('New York');
            // trainNetwork.removeVertex(atlantaStation);
            trainNetwork.addEdge(atlantaStation, newYorkStation, 800);
            trainNetwork.removeEdge(atlantaStation, newYorkStation);
            trainNetwork.print();

            module.exports = Graph;

            // Edge.js
            class Edge {
                constructor(start, end, weight = null) {
                    this.start = start;
                    this.end = end;
                    this.weight = weight;
                }
            }

            module.exports = Edge;
        
        Adding Vertices
            Currently, we would have to manually create a new Vertex instance and add it into the Graph’s list of vertices to populate the graph. 
            If we create an .addVertex() method in the Graph class, it simplifies the process of adding a vertex to the graph. 
            This alleviates the burden of knowing how the Vertex class should interact with the Graph class for whoever is using our Graph. 
            They only need to interact with the Graph class.

        Removing Vertices
            We also want our Graph to manage its own vertex removal, just like how it handles its own vertex creation.
            We will use the .removeVertex() method to look for the requested vertex and remove it from the list of vertices.


        Connecting Vertices with Edges
            Since we can add vertices to our graph, we should be able to connect them together. 
            We want to provide this functionality in the Graph class to add a layer of abstraction that will simplify adding edges, similar to how we abstracted vertex creation. 
            This is where our Edge class in Edge.js will come in handy. Go ahead and take a look at the class.

            The start and end properties mark the vertices that the edge connects. If the graph is directed, we can indicate the direction the edge points (towards the end vertex).
            We will create an .addEdge() method in the Vertex class that connects the vertices together by creating an Edge and adding it to the vertices’ list of edges. 
            When the Edge is created, it expects the two Vertex instances, which is how the Edge tracks the connection between the two vertices .

            Then, we will use this method in the Graph‘s .addEdge() method to create edges going in both directions between the two given vertices. Even though this graph is undirected, we want to create two edges going in both directions so it is easier to traverse.

        Removing Vertex Connections
            Now that we can connect vertices together, we want make the Graph more flexible by giving it the ability to remove connections.
            We will use the .removeEdge() method to remove any Edge between the given vertex instances.

        Weighted Graphs
            The current implementation of our Graph class is unweighted, where there is no cost associated with the edge that connects the vertices together. 
            Since we want our Graph to be flexible, we should give the option for weights to be added to the edge when a new edge is created.

        Directed Graphs
            So far we have only built out support for undirected graphs. Next, we will focus on expanding our Graph class to be directed, where there does not necessarily have to be edges going in both directions between the vertices, as we have done with undirected graphs.
            The main difference between the undirected graph and directed graph is that our undirected graph uses two edges going in opposite directions to indicate that there is a connection between two vertices.

        Graph Review
            Let’s put our Graph class to use and build out our train network. This time we will use it to map out all the train stations and routes that our rail service operates. We will also want to make sure that our routes can track the distance between each station.
            For this exercise, we will build out the train network inside trainNetwork.js.
        
    > Graph Traversals
        There are many ways to traverse a graph, but you will focus on three methods: 
            - depth-first search (DFS), 
                Simply put, a depth-first graph search continues down a path until it reaches the end. 
                It is helpful for determining if a path exists between two vertices. 
                DFS has many applications, including topological sorting and detecting cycles, but one of the more interesting real-world applications is that it can be used to solve problems that have a singular correct answer (a path between the start state and end state), such as a sudoku exercise.
            - breadth-first search (BFS), and 
                On the other hand, a breadth-first graph search approach checks the values of all neighboring vertices before moving into another level of depth. 
                This is an incredibly inefficient way to find just any path between two vertices, but it’s an excellent way to identify the shortest path between them. 
                Because of this, BFS is helpful for figuring out directions from one place to another.
            - Dijkstra’s algorithm. 
                Dijkstra’s algorithm is a method for finding the shortest distance from a given point to every other point in a weighted graph. 
                The algorithm works by keeping track of all the distances and updating the distances as it conducts a breadth-first search. 
                A common application of this algorithm is to find the quickest route from one destination to another.
        These traversal methods are core algorithms for searching a graph.

        GRAPH SEARCH: CONCEPTUAL
            Graph Search Conceptual Introduction
                Using graphs to model complex networks is pretty swell, but one way that graphs can really come in handy is with graph search algorithms. You can use a graph search algorithm to traverse the entirety of a graph DS in search of a specific vertex value.
                There are two common approaches to using a graph search to progress through a graph:
                    - depth-first search, known as DFS follows each possible path to its end
                    - breadth-first search, known as BFS broadens its search from the point of origin to an ever-expanding circle of neighboring vertices
            To enable searching, we add vertices to a list, visited. This list is pretty important because it keeps the search from visiting the same vertex multiple times! This is particularly vital for cyclical graphs where you might otherwise end up in an infinite loop.

            So how do you calculate the runtime for graph search algorithms?

            In an upper bound scenario, we would be looking at every vertex and every edge. 
            Because of this, the big O runtime for both depth-first search and breadth-first search is O(vertices + edges).
            
        Depth-First Search (DFS) Conceptual
            Imagine you’re in a car, on the road with your friend, “D.” D is on a mission to get to your destination by process of elimination. D won’t stop and ask for directions. D just sticks to a chosen path until you reach the end.
            At that point, if the end wasn’t actually your destination, D brings you back to the last point when there was an intersection and tries another path.
            Like your friend D, depth-first search algorithms check the values along a path of vertices before moving to another path.
            While this isn’t exactly ideal when you want to find the shortest path between two points, DFS can be very helpful for determining if a path even exists.
            In order to accomplish this path-finding feat, DFS implementations use either a stack DS or, more commonly, recursion to keep track of the path the search is on and the current vertex.
            In a stack implementation, the most recently added vertex is popped off the stack when the search has reached the end of the path. Meanwhile, in a recursive implementation, the DFS function is recursively called for each connected vertex.

        Breadth-First Search (BFS) Conceptual
            You’re back in a car, but this time, your friend “B” is navigating. Unlike D, B is a bit hesitant about whether you’ve gone the right way and keeps checking in to see if you are on the best path. At each intersection, B tries out each possible route one by one, but only for a block in each direction to see if you’ve found your destination.
            Like B, breadth-first search, known as BFS, checks the values of all neighboring vertices before moving into another level of depth.
            This is an incredibly inefficient way to find just any path between two points, but it’s an excellent way to identify the shortest path between two vertices. Because of this, BFS is helpful for figuring out directions from one place to another.
            Unlike DFS, BFS graph search implementations use a queue DS to keep track of the current vertex and vertices that still have unvisited neighbors. In BFS graph search a vertex is dequeued when all neighboring vertices have been visited.

        Graph Search Traversal Order
            What if you don’t need to find a path, but you do need to get a list of all the values in a graph?
            Well, it turns out that in addition to path-finding, depth-first search is pretty adept at organizing vertices (or vertex values) with a clear order of visitation from beginning to end.

            There are three main traversal orders that you’ll come across for graph traversal:
                - Preorder, in which each vertex is added to the “visited” list and added to the output list BEFORE getting added to the stack
                - Postorder, in which each vertex is added to the “visited” list and added to the output list AFTER it is popped off the stack
                - Reverse Post-Order (also known as Topological Sort), which returns an output list that is exactly the reverse of the post-order list
            Take a look at the directed graph structure we have depicted here. Let’s say that we want a list of all vertex values, starting with “Lasers”, in the order that they are added to the stack.

            A pre-order DFS traversal would come in handy and we might end up with the following list. (We’ll assume here that this algorithm prefers visiting things in alphabetical order if there is a choice.):

            ["Lasers", "Lava", "Snakes", "Spikes", "Piranhas"]
            Now, let’s say we want the same values, but with each value only added to the list once its vertex has been popped from the stack. In this case, our post-order DFS traversal would result in a list that looked like:

            ["Spikes", "Snakes", "Lava", "Piranhas", "Lasers"]
            You may notice that the post-order list is not the reverse of the pre-order list. A reverse post-order list would still begin with “Lasers”, but then begin to differ:

            ["Lasers", "Piranhas", "Lava", "Snakes", "Spikes"]
            What happens if there are unvisited vertices that are not reachable from the current path? The search would visit them in (here alphabetical) order after exploring the current path.
        
        Graph Search Conceptual Review
            - You can use a graph search algorithm to traverse the entirety of a graph DS to locate a specific value
            - Vertices in a graph search include a “visited” list to keep track of whether or not each vertex has been checked
            - Depth-first search (DFS) and breadth-first search (BFS) are two common approaches to graph search
            - The runtime for graph search algorithms is O(vertices + edges)
            - DFS, which employs either recursion or a stack DS, is useful for determining whether a path exists between two points
            - BFS, which generally relies on a queue DS, is helpful in finding the shortest path between two points
            - There are three common traversal orders which you can apply with DFS to generate a list of all values in a graph: pre-order, post-order, and reverse post-order
        
        GRAPH TRAVERSAL: JAVASCRIPT
        Depth-First Traversal (One path)
            Traversals are incredibly useful when you are trying to find a particular value or a particular path in a graph. We’ll first explore the depth-first traversal function for traversing through a directed graph. To recap, depth-first traversals iterate down each vertex, one neighbor at a time, before going back up and looking at the neighbor’s connected vertices. In this exercise, we will focus on traversing down the full length of one path and logging each vertex’s data value.
            For simplicity, we’ll implement the traversal iterator as a separate function instead of as a method on the Graph class. In other implementations, the iterator can be seen as a class method.
            We have also set up a sample graph in testGraph.js for you to test the traversals against. Feel free to take a look at the file to familiarize yourself with the structure of the graph.


            // depthFirstTraversal.js
            const testGraph = require('./testGraph.js');

            const depthFirstTraversal = (start, visitedVertices = [start]) => {
                console.log(start.data)
                
                if (start.edges.length) {
                    const neighbor = start.edges[0].end;
                    if (!visitedVertices.includes(neighbor)) {
                        visitedVertices.push(neighbor);
                        depthFirstTraversal(neighbor, visitedVertices);
                    }
                }
            };

            depthFirstTraversal(testGraph.vertices[0]);


            // testGraph.js
            const { Graph } = require('./Graph.js');

            const simpleGraph = new Graph(true, false);
            const startNode = simpleGraph.addVertex('v0.0.0');
            const v1 = simpleGraph.addVertex('v1.0.0');
            const v2 = simpleGraph.addVertex('v2.0.0');

            const v11 = simpleGraph.addVertex('v1.1.0');
            const v12 = simpleGraph.addVertex('v1.2.0');
            const v21 = simpleGraph.addVertex('v2.1.0');

            const v111 = simpleGraph.addVertex('v1.1.1');
            const v112 = simpleGraph.addVertex('v1.1.2');
            const v121 = simpleGraph.addVertex('v1.2.1');
            const v211 = simpleGraph.addVertex('v2.1.1');

            simpleGraph.addEdge(startNode, v1);
            simpleGraph.addEdge(startNode, v2);

            simpleGraph.addEdge(v1, v11);
            simpleGraph.addEdge(v1, v12);
            simpleGraph.addEdge(v2, v21);

            simpleGraph.addEdge(v11, v111);
            simpleGraph.addEdge(v11, v112);
            simpleGraph.addEdge(v12, v121);
            simpleGraph.addEdge(v21, v211);

            module.exports = simpleGraph;


        Depth-First Traversal (All paths)
            We’ve gotten the hang of traversing down one path, but we want to traverse down all the paths (not just the first possible path). We will modify our existing implementation to iterate down all the other paths by using a .forEach() loop to iterate through all of the start vertex’s edges.
            We won’t have to worry about iterating through all the neighbors before going down the neighbor’s first connected vertex. This is because the recursive call occurs before the next iteration of the for loop.
            Instructions
                1.To traverse down all paths, we no longer need the if statement to check if there are edges to traverse. Instead, we will use an iterator to go through all of the vertex’s edges. If there are no edges, then the edges array would be empty and nothing would happen.
                Replace the if statement with a .forEach() iterator that iterates through the start vertex’s list of edges.
                We will also want to set the neighbor to the end vertex of the edge parameter. The end vertex is given as a parameter by the .forEach() iterator.

                2.Great, we have completed the depth-first traversal! It iterates down each path until it hits a dead end, continues down the next path at the neighboring vertex until it hits a dead end, and so on.
                To see this in action, we have provided you with a sample graph called testGraph and passed it in our call to depthFirstTraversal(). You should see the traversal move in the following order: v0.0.0, v1.0.0, v1.1.0, v1.1.1, v1.1.2, v1.2.0, v1.2.1, v2.0.0, v2.1.0, and v2.1.1.

                // depthFirstTraversal.js
                const testGraph = require('./testGraph.js');

                const depthFirstTraversal = (start, visitedVertices = [start]) => {
                    console.log(start.data);

                    start.edges.forEach(edge => {
                        const neighbor = edge.end;

                        if (!visitedVertices.includes(neighbor)) {
                        visitedVertices.push(neighbor);
                        depthFirstTraversal(neighbor, visitedVertices);
                        }
                    });
                };

                depthFirstTraversal(testGraph.vertices[0]);

                // testGraph.js - same as before
                
        Depth-First Traversal (Callbacks)
            Our current implementation of the depth-first traversal simply prints out the vertices of the graph as they are traversed. This would be useful in scenarios where we want to see the order that the traversal occurs in. For example, if the graph was an instruction list, we need the exact order that the steps will occur to determine which dependencies need to be resolved first.
            However, there may be other instances where we want to do something other than printing out the traversal order. For example, if we just need to determine if a path exists, like seeing if a maze is solvable, we just need a true or false value. We can do this by opening up a callback parameter for the user.
            Instructions
                1.Since we want to open up another parameter as a callback, add another parameter to depthFirstTraversal() called callback as the second parameter.
                In the recursive call to depthFirstTraversal(), add the callback argument.
                We want to avoid making the callback the third parameter to simplify depthFirstTraversal() for the user. This means they won’t be forced to supply the visitedVertices parameter if they also want to override the default callback argument.

                2.Now let’s put the callback to work. Replace the call to console.log() with a call to callback() and pass in the start vertex.
                To test the new callback, add a function as a second argument to depthFirstTraversal() at the bottom of depthFirstTraversal.js. This function should accept a vertex as an argument and print out the data property. Since we passed in a print function as our callback, we should still see the order that the vertices are traversed in.
                This wraps up our implementation of depth-first traversal! If you’re feeling up for it, here are some challenge tasks to tackle:

                This is currently a pre-order traversal. How would you modify the implementation to be a post-order traversal?
                How would you modify the implementation to use a queue instead of recursion?

                // depthFirstTraversal.js
                const testGraph = require('./testGraph.js');

                const depthFirstTraversal = (start, callback, visitedVertices = [start]) => {
                    callback(start);

                    start.edges.forEach((edge) => {
                        const neighbor = edge.end;

                        if (!visitedVertices.includes(neighbor)) {
                        visitedVertices.push(neighbor);
                        depthFirstTraversal(neighbor, callback, visitedVertices);
                        }
                    });
                };

                depthFirstTraversal(testGraph.vertices[0], (vertex) => { console.log(vertex.data) });

                // testGraph.js - same as before
        
        Breadth-First Traversal (First layer)
            Now it’s time to focus on breadth-first traversal! Just as a reminder, breadth-first iterates through the whole graph in layers by going down one layer, which comprises the start vertex’s direct neighbors. Then it proceeds down to the next layer which consists of all the vertices that are neighbors of the vertices in the previous layer.
            For this exercise, let’s focus on traversing down one layer. We will take a similar approach as we did with the depth-first traversal by keeping an array of visitedVertices to prevent us from iterating through the same vertices.
            However, we will iterate through all of the direct neighbor vertices instead of iterating down the neighbor’s first edge. We will also use a queue to traverse through the graph instead of recursion to explore the different ways we can implement the traversals.
            Instructions
                1.Let’s start by creating our breadthFirstTraversal() function. We should expect for the graph to be provided in the form of the starting vertex.
                Add the start vertex as a parameter to breadthFirstTraversal() .

                2.Next, we will go down one layer and traverse all of the start vertex’s neighbor. Set up a .forEach() iterator to iterate through all of its edges.
                Each edge contains the neighboring vertex in its end property, which will be our neighbor. Create a const variable, neighbor, and set it to the end property of each edge.

                3.Great! Now we should set up our list of visitedVertices so we can mark the neighbor vertex as “visited”. We won’t need to provide the visitedVertices as an argument since we are using a queue to traverse through the graph instead of recursion.
                Inside the function and before the forEach loop, create a const variable, visitedVertices. Set it to an array with the start vertex as the first element.

                4.Almost there! Before we can mark the neighbor as “visited”, we need to check that the visitedVertices does not already include the neighbor vertex. Otherwise, we could end up “visiting” the vertices multiple times by adding duplicates of the vertex in our visitedVertices list.
                After the neighbor vertex is declared, add an if statement that checks that the neighbor is not included in the visitedVertices. If the neighbor is not, then we can mark it as “visited” by adding it to the list of visitedVertices.

                5.We’ve now successfully iterated through all of the start vertex’s neighbors. To check that we are “visiting” the vertices in the correct order, print out the visitedVertices right before the end of the function.
                When we run the function with our test graph, we should see the vertices in the following order: v0.0.0, v1.0.0, and v2.0.0.

                // breadthFirstTraversal.js
                const testGraph = require('./testGraph.js');

                const breadthFirstTraversal = (start) => {
                    const visitedVertices = [start];
                    start.edges.forEach(edge => {
                        const neighbor = edge.end;
                        if (!visitedVertices.includes(neighbor)) {
                        visitedVertices.push(neighbor)
                        }
                    });
                    console.log(visitedVertices)
                };

                breadthFirstTraversal(testGraph.vertices[0]);

                // testGraph.js - same as before

        Breadth-First Traversal (All layers)
            So far, we can iterate down one layer, but we have yet to iterate down the remaining layers. In order to do so, we will introduce a queue that will keep track of all of the vertices to visit.
            As we iterate through the neighbors, we will add its connected vertices to the end of the queue, pull off the next neighbor from the queue, add its connected vertices, and so on. This way allows us to maintain the visiting order; we will visit the vertices across the same layer while queueing up the next layer. When there are no vertices left in the current layer, the vertices of the next layer are already queued up, so we move down and iterate across the next layer.
            We will use our implementation of the Queue DS that was covered in a previous course. It is located in Queue.js. Go ahead and take a quick look to refresh your memory of the DS and the available methods.
            Instructions
                1.We will create our queue with the start vertex as the first connected vertex to iterate through.
                Right after we create our list of visitedVertices, create a const variable, visitQueue. Instantiate a new Queue and assign it to the visitQueue.
                Then .enqueue() the start vertex to the queue.

                2.When we are looking at a vertex from visitQueue, we want to dequeue it so that we don’t look at it again. The visitedVertices array ensures that it does not get enqueued into visitQueue again.
                Before the .forEach() iterator, .dequeue() the next vertex from the visitQueue and assign it to the current variable with const. Go ahead and print out the data property of the current vertex so we can see which vertex we’re looking at.

                3.The queue holds all of the vertices that we have yet to iterate through. This means we want to continue iterating through these vertices as long as there are vertices left in the queue.
                After we enqueue the start vertex, add in a while loop that continues to run as long as the visitQueue is not empty. Make sure that it includes dequeuing the next vertex and the forEach() iterator, since we also want to update visitedVertices if there are still vertices in the queue.

                4.Next, we want to iterate through the current vertex’s neighbors and enqueue them, not just the start vertex’s neighbors.
                Update the .forEach() iterator to iterate through the current vertex’s edges instead. Then, inside the .forEach() iterator, if the visitedVertices does not include the neighbor, we should enqueue the neighbor to the visitQueue.

                5.That’s it! When we run the graph traversal with the testGraph, we should see the vertices printed out in the following order: v0.0.0, v1.0.0, v2.0.0, v1.1.0, v1.2.0, v2.1.0, v1.1.1, v1.1.2, v1.2.1, and v2.1.1.
                If you’re feeling up for a challenge, take a moment to consider the following:

                How would you modify this to take a recursive approach?
                How would you add in a callback to expand the utility of the function?


                // breadthFirstTraversal.js
                const testGraph = require('./testGraph.js');
                const Queue = require('./Queue.js');

                const breadthFirstTraversal = (start) => {
                    const visitedVertices = [start];
                    const visitQueue = new Queue();
                    visitQueue.enqueue(start);
                    while (!visitQueue.isEmpty()) {
                        const current = visitQueue.dequeue();
                        console.log(current.data);
                        current.edges.forEach((edge) => {
                            const neighbor = edge.end;
                            if (!visitedVertices.includes(neighbor)) {
                                visitedVertices.push(neighbor);
                                visitQueue.enqueue(neighbor);
                            }
                        })
                    }
                };
                breadthFirstTraversal(testGraph.vertices[0]);
                
    > Dijkstra's Algorithm
        DIJKSTRA'S ALGORITHM: CONCEPTUAL
            One of the most common applications of graph searches is to find the shortest distance between vertices. Finding this distance has a variety of applications such as finding the optimal route to a destination or transferring data in a computer network.
            Take a look at the graph below. Finding the shortest path between vertex A and vertex E may seem easy in your brain, but telling a computer how to find it is a bit more complicated.
            Graph
            Fortunately, there is an algorithm that computes the shortest distance from a given vertex to the rest of the vertices in a graph. This is called Dijkstra’s Algorithm.
            Dijkstra’s Algorithm works like the following:
            - Instantiate a dictionary that will eventually map vertices to their distance from the start vertex
            - Assign the start vertex a distance of 0 in a min heap
            - Assign every other vertex a distance of infinity in a min heap
            - Remove the vertex with the smallest distance from the min heap and set that to the current vertex
            - For the current vertex, consider all of its adjacent vertices and calculate the distance to them as (distance to the current vertex) + (edge weight of current vertex to adjacent vertex).
            - If this new distance is less than the current distance, replace the current distance.
            - Repeat 4 and 5 until the heap is empty
            - After the heap is empty, return the distances
        
        Dijkstras Algorithm: Conceptual Runtime
            How efficient is Dijkstra’s algorithm? Let’s break it into different parts:
                - Searching through the graph
                - Keeping track of distances
            Just like breadth-first search and depth-first search, to search through an entire graph, in the worst case, we would go through all of the edges and all of the vertices resulting in a runtime of O(E + V).
            For Dijkstra’s, we use a min-heap to keep track of all the distances. Searching through and updating a min-heap with V nodes takes O(log V) because in each layer of the min-heap, we reduce the number of nodes we are looking at by a factor of 2.

        Min-Heap
            In the worst case, we would update the min-heap every iteration. Since there are at most E + V iterations of Dijkstra’s and it takes log V to update a min-heap in the worst case, then the runtime of Dijkstra’s is O((E+V)log V).

        Dijkstras Algorithm Review
            - Dijkstra’s algorithm is an algorithm to find all of the shortest distances between a start vertex and the rest of the vertices in a graph.
            - The algorithm works by keeping track of all the distances and updating the distances as it conducts a breadth-first search.
            - Dijkstra’s algorithm runs in O((E+V)log V).

        DIJKSTRA'S ALGORITHM: JAVASCRIPT
        Setup
            Dijkstra’s Algorithm is used for evaluating the shortest paths between vertices in a graph. The general strategy is to iterate through the vertices in such a way that will always allow us to only consider the shorter path at each vertex and maintain every possible shortest path as we go.
            We will first implement the algorithm to find the shortest distance to every vertex. Our implementation will take the following steps:

            Evaluate the distances between the starting vertex and its neighbors
            If the new distance to the neighbor is lower than the previous distance, record it, and queue up the neighbor
            Dequeue the next vertex to evaluate
            Repeat steps 2 - 3 until there are no more vertices left in the queue.
            In this exercise, we will set up the objects that will keep track of the shortest distances between the starting vertex and each other vertex, and the shortest paths.

            We will be using a priority queue, which is a specialized heap DS, to maintain the vertices we need to evaluate next. We’ll explain in a later exercise exactly what it is and the reason for using it instead of a regular queue.

            We have also set up a test graph for you in testGraph.js to test the output of the function as you complete the exercises.

            Instructions
            1.To begin, we need to provision our dijkstras() function with two parameters: graph and startingVertex. graph is the actual DS instance. startingVertex indicates the starting point from which we will construct the paths.
            In the dijkstras() function, specify the graph as the first parameter and startingVertex as the second parameter.

            2.We will want to keep track of the total distances for the shortest paths to each vertex. In the dijkstras() function, create a distances variable and set it to an empty object. distances will be used to map each vertex to the distance of its path to the starting vertex.
            Before we can start evaluating the paths, we also need to initialize each vertex’s distance to Infinity. Any connection will be shorter than Infinity, no matter how large the weight is. As long as there is a connection between two vertices, the connection will always be recognized as part of the shortest path over Infinity.
            Iterate through the graph’s vertices using .forEach(). In the distances object, assign each vertex’s data to Infinity. We want the key to be the vertex’s data property and not the vertex itself to make it easier to read and access.

            3.The last thing we want to track is the shortest paths to each vertex. Instead of recording the full path to every vertex, we just need the previous vertex. This is because we are guaranteed that the vertices leading up to the previous vertex are also the shortest distance, and we can reconstruct the full path by tracing through each vertex’s previous vertex.
            After distances is created, create a variable, previous, and set it equal to an empty object. This will be a map of every vertex to its corresponding previous vertex.
            We will also need to initialize the vertices in the previous object. In the iterator and after the distances are initialized, map each vertex’s data in the previous object to null. This accounts for situations where the graph is disconnected, or there are vertices that do not have edges leading to them.

            4.Now, you may be wondering, “but the distance from the starting vertex to the starting vertex is 0, not Infinity!” Let’s resolve this by adjusting the initial distance for the starting vertex.
            After we finish iterating through the graph’s vertices, set the distance of the startingVertex.data in distances to 0.

            5.Great! Now we want to return the results of our evaluations in distances and previous. This allows for the user who makes a call to our function to use these computed values.
            You can return both values by returning an object with distances and previous keys set to their respective variables.

            6.Let’s go ahead and check our output for dijkstras() to make sure we set up our distances and previous paths correctly.
            After the dijkstras() function, we have already set up a call to the function with the testGraph and the first vertex in the graph, A, as the starting vertex. The output is stored in results.
            Print out the results. In the distances, we should see A with a distance of 0 and the remaining vertices in the graph mapped to Infinity. In previous, we should see every vertex in the graph mapped to null.

                // dijkstras.js
                const testGraph = require('./testGraph.js');

                const dijkstras = (graph, startingVertex) => {
                    const distances = {};
                    const previous = {};

                    graph.vertices.forEach((vertex) => {
                        distances[vertex.data] = Infinity;
                        previous[vertex.data] = null;
                    });

                    distances[startingVertex.data] = 0;

                    return { distances, previous };
                };

                const results = dijkstras(testGraph, testGraph.vertices[0]);
                console.log(results);

                module.exports = dijkstras;


                // testGraph.js
                const { Graph } = require('./Graph.js');

                const testGraph = new Graph(true, true);
                const a = testGraph.addVertex('A');
                const b = testGraph.addVertex('B');
                const c = testGraph.addVertex('C');
                const d = testGraph.addVertex('D');
                const e = testGraph.addVertex('E');
                const f = testGraph.addVertex('F');
                const g = testGraph.addVertex('G');

                testGraph.addEdge(a, c, 100);
                testGraph.addEdge(a, b, 3);
                testGraph.addEdge(a, d, 4);
                testGraph.addEdge(d, c, 3);
                testGraph.addEdge(d, e, 8);
                testGraph.addEdge(e, b, -2);
                testGraph.addEdge(e, f, 10);
                testGraph.addEdge(b, g, 9);
                testGraph.addEdge(e, g, -50);

                module.exports = testGraph;

        Evaluate Paths to Starting Vertex’s Neighbors
            We have all of our records set up, so we can start traversing through the graph and evaluating the distances from the starting vertex to its neighbors.
            In the evaluation of each neighbor, we compare the distance of the new path to the distance of the previous path. If the distance of the new path is shorter, we will update our records of distances and previous vertices with the new path.
            Every time we evaluate an edge between a vertex and its neighbor, the if condition ensures that the record will always maintain the shortest path among the evaluations so far. This is why we can use the previously recorded distance for comparison in our evaluation.
            Instructions
            1.Let’s start evaluating the distances to the starting vertex’s neighbors by iterating through its list of edges.
            Right before we return the recorded results, create a const variable, vertex, and set it to startingVertex. Then use a .forEach() iterator to go through the vertex’s list of edges. We will use the edge argument for this iterator.

            2.On each iteration through the edges, we are evaluating an alternate path to a different neighbor. The distance of the new path is the sum of the distance from the vertex to the neighbor and the distance from the starting vertex to the vertex.
            Inside the .forEach() iterator, create a const variable, alternate, and set it to the sum of the edge’s weight and the value of the vertex’s distance in distances.

            3.Now we can compare the distance of the new alternate path to the distance of the last recorded path to the neighbor. The distance of the neighbor’s last recorded path is in the distances object at the neighbor’s data.
            Let’s use a variable to hold the key that we will use to access the neighbor’s distance in distances. This will help with code readability.
            Still in the .forEach(), create a const variable, neighborValue, and set it to the data property of the neighbor, which is located in the end property of the edge.
            Set up an if condition that checks if the alternate distance is shorter than the value at neighborValue in distances.

            4.If the condition is satisfied, then we have found a shorter path and should update the neighbor’s recorded distance and previous vertex.
            If the alternate path is shorter, set distances at the neighborValue to the new alternate cost. We also want to set the previous vertex at the neighborValue to vertex.

            5.When we evaluate the distances, we are determining if the path from the starting vertex to the neighbor is shorter than the previously evaluated distance. Since we have not evaluated any paths to the neighbors yet, the previously recorded distances to all of the neighbors is Infinity.
            Run the code and look at the output of the function. The shortest paths evaluated so far should be the paths from the starting vertex to its neighbors. In distances we should see the starting vertex with a distance of 0, its neighbors set to the evaluated distances, and all other vertices with Infinity distances. In previous, we should see the neighbors with the starting vertex as their previous vertex, and all other vertices with null.

                // dijkstras.js
                const testGraph = require('./testGraph.js');

                const dijkstras = (graph, startingVertex) => {
                    const distances = {};
                    const previous = {};

                    graph.vertices.forEach((vertex) => {
                        distances[vertex.data] = Infinity;
                        previous[vertex.data] = null;
                    });
                    distances[startingVertex.data] = 0;

                    const vertex = startingVertex;                              // add this chunk of code
                    vertex.edges.forEach((edge) => {                            
                        const alternate = edge.weight + distances[vertex.data];
                        const neighborValue = edge.end.data;

                        if (alternate < distances[neighborValue]) {
                            distances[neighborValue] = alternate;
                            previous[neighborValue] = vertex;
                        }
                    })

                    return { distances, previous };
                };

                const results = dijkstras(testGraph, testGraph.vertices[0]);
                console.log(results);

                module.exports = dijkstras;

        

        Evaluate All Paths
            Currently, we’re evaluating the distances to the neighbors of the starting vertex, but we want to expand this to every connected vertex in the graph. Every time we discover a shorter path to a neighbor, we should queue up the neighbor to explore its connections and evaluate them.
            This will accomplish two things:
            Any paths that have not yet been explored will be explored
            For vertices that already have a path found, we will re-evaluate if the alternate path through the neighbor will result in a shorter distance.
            We are guaranteed that every vertex is evaluated because whenever a path is found to a vertex, then it will be queued up and its neighbors will be evaluated. The only way for a vertex to escape evaluation is if there are no connections to the vertex.
            For our queue, we will use a priority queue. A priority queue is a specialized form of a min-heap, where the priority of a piece of data is stored alongside data, elements are popped based on the priority value. We have provided the MinHeap.js file for you in case you want a refresher on a basic heap DS. In the meantime, take a look through PriorityQueue.js to familiarize yourself with the DS. We mainly need the .add() method to queue up elements with a priority, and the .popMin() method to grab the element with the lowest priority.
            This priority queue is better than a regular queue since it allows us to evaluate the vertices with the shortest distances first. This way we can avoid unnecessarily re-evaluating paths later in the queue since it is less likely that a longer path will result in a shorter distance.

            Instructions
            1.First, let’s set up the Priority Queue that we will use to hold the vertices we will evaluate as we traverse through the graph.
            Right after the previous object is instantiated, create a const variable, queue, and set it to a new instance of a PriorityQueue.
            The first vertex we want to evaluate is the starting vertex. After instantiating the queue, make a call to .add() the starting vertex to the queue. Pass in an object with the vertex property set to the startingVertex, and the priority property set to 0. The priority is the vertex’s distance to the starting vertex.

            2.Currently, we are iterating through the startingVertex’s edges and calculating the distance of the alternate path using the startingVertex’s distance. Now, we want to shift to evaluate the vertices in the queue.
            Instead of setting the vertex variable to the starting vertex, we want to set it to the vertex with the smallest priority in the queue, which will initially be the starting vertex. Dequeue the vertex with the smallest priority from the queue by calling the .popMin() method and declare the vertex variable by destructuring it from the resulting object.

            3.For now, we only have the startingVertex queued up for evaluation. However, we also want to queue up any neighbors where a shorter distance from the vertex to the neighbor is found. This is because other paths that go through this neighbor could be shorter than what was previously recorded.
            If the alternate path to the neighbor is shorter than the previously recorded distance, .add() the vertex’s neighbor to the queue where the vertex property is set to the neighbor, and the priority is the new neighborValue in distances.

            4.Great! Our queue is running along, so we just need to set up a loop to go through all of the vertices in the queue. As long as there are vertices left in the queue, we should continue evaluating alternate paths.
            After the distance of startingVertex is set to 0, set up a while loop that continues to evaluate the distances as long as the queue is not empty. You can call .isEmpty() on queue to check if it is empty or not. This should come right before the vertices are popped from the queue and end right after we iterate through the neighbors.

            5.Awesome job! We’ve gotten through the basis of Dijkstra’s. Run the function on the test graph and print out the result, you should see the following shortest distances:
            A: 0
            B: 3
            C: 7
            D: 4
            E: 12
            F: 22
            G: -38
            These should be the following previous vertices:
            A: null
            B: A
            C: D
            D: A
            E: D
            F: E
            G: E


                // dijkstras.js
                const PriorityQueue = require('./PriorityQueue.js');
                const testGraph = require('./testGraph.js');

                const dijkstras = (graph, startingVertex) => {
                    const distances = {};
                    const previous = {};
                    const queue = new PriorityQueue();

                    queue.add({ vertex: startingVertex, priority: 0 });

                    graph.vertices.forEach((vertex) => {
                        distances[vertex.data] = Infinity;
                        previous[vertex.data] = null;
                    });

                    distances[startingVertex.data] = 0;

                    while (!queue.isEmpty()) {
                        const { vertex } = queue.popMin();

                        vertex.edges.forEach((edge) => {
                            const alternate = edge.weight + distances[vertex.data];
                            const neighborValue = edge.end.data;

                            if (alternate < distances[neighborValue]) {
                                distances[neighborValue] = alternate;
                                previous[neighborValue] = vertex;

                                queue.add({ vertex: edge.end, priority: distances[neighborValue] })
                            }
                        })
                    }

                    return { distances, previous };
                };

                const results = dijkstras(testGraph, testGraph.vertices[0]);
                console.log(results);

                module.exports = dijkstras;


                // testGraph.js - the same
                //MinHeap.js - the same DS

                // PriorityQueueu.js
                class PriorityQueue {
                    constructor() {
                        this.heap = [null];
                        this.size = 0;
                    }

                    add({vertex, priority}) {
                        this.heap.push({vertex, priority});
                        this.size++;
                        this.bubbleUp();
                    }

                    isEmpty() {
                        return this.size === 0;
                    }

                    popMin() {
                        if (this.size === 0) {
                        return null 
                        }
                        const min = this.heap[1];
                        this.heap[1] = this.heap[this.size];
                        this.size--;
                        this.heap.pop();
                        this.heapify();
                        return min;
                    }

                    bubbleUp() {
                        let current = this.size;
                        while (current > 1 && this.heap[getParent(current)].priority > this.heap[current].priority) {
                        this.swap(current, getParent(current));
                        current = getParent(current);
                        }
                    }

                    heapify() {
                        let current = 1;
                        let leftChild = getLeft(current);
                        let rightChild = getRight(current);
                        // Check that there is something to swap (only need to check the left if both exist)
                        while (this.canSwap(current, leftChild, rightChild)){
                        // Only compare left & right if they both exist
                        if (this.exists(leftChild) && this.exists(rightChild)) {
                            // Make sure to swap with the smaller of the two children
                            if (this.heap[leftChild].priority < this.heap[rightChild].priority) {
                            this.swap(current, leftChild);
                            current = leftChild;
                            } else {
                            this.swap(current, rightChild);
                            current = rightChild;
                            }
                        } else {
                            // If only one child exist, always swap with the left
                            this.swap(current, leftChild);
                            current = leftChild;
                        }
                        leftChild = getLeft(current);
                        rightChild = getRight(current);
                        }
                    }

                    swap(a, b) {
                        [this.heap[a], this.heap[b]] = [this.heap[b], this.heap[a]];
                    }

                    exists(index) {
                        return index <= this.size;
                    }

                    canSwap(current, leftChild, rightChild) {
                        // Check that one of the possible swap conditions exists
                        return (
                        this.exists(leftChild) && this.heap[current].priority > this.heap[leftChild].priority
                        || this.exists(rightChild) && this.heap[current].priority > this.heap[rightChild].priority
                        );
                    }
                }

                const getParent = current => Math.floor((current / 2));
                const getLeft = current => current * 2;
                const getRight = current => current * 2 + 1;

                module.exports = PriorityQueue;
                

        Shortest Path to a Target Vertex
            Our current implementation of Dijkstra’s returns the shortest paths for all of the vertices in the graph. We can build upon this to create a function in shortestPath.js that reconstructs the full path to one vertex.
            We will need to make a call to dijkstras() to get the map of distances and previous vertices. From there we can grab the target vertex’s shortest distance from distances and build the entire path using the previous vertices.
            We cannot do this while dijkstras() continues to calculate the paths, because we cannot guarantee that the first encounter of the target vertex is the shortest path. Doing it after all the paths have been evaluated covers the possibility that an alternate path later in the queue will be shorter than the first one, particularly when there are negative distances.
            Instructions
            1.We should first supply our shortestPathBetween() function with the graph, starting vertex, and target vertex.
            Add 3 parameters to the shortestPathBetween() function: graph, startingVertex, and targetVertex.

            2.Now we should make a call to dijkstras() to retrieve the shortest distances and previous vertices.
            Call dijkstras() and pass the given graph and startingVertex as arguments. Destructure distances and previous from the resulting output.

            3.We will want to return the shortest distance from the starting vertex to the target vertex. We can access this in distances using the targetVertex’s data.
            After the call to dijkstras(), create a distance variable and set it to the target vertex’s shortest distance in distances.
            Then, return the distance in an object with the distance property set to distance.

            4.We also want to construct the path and return it back. Since each entry in previous is a reference to the previous vertex in the shortest path, we can walk backwards through the previous vertices and store the vertex in our path. This is similar to a linked list traversal, just in reverse.
            After the distance is created, create another variable, path, and set it to an empty array. Go ahead and add the path to the return object.
            Then create a temporary variable, vertex, and set it to the targetVertex. This is the end of the path where we will start our backwards traversal.

            5.We will add the vertex into the path, set the next vertex to the previous vertex, and repeat until there are no vertices left in the path. To do this, we will set up a while loop to control the iterations.
            When there are no vertices left, then the vertex will be null. After the temporary vertex is initialized, set up a while loop that continues to run as long as vertex is not null.
            Inside the loop, .unshift() the vertex into the path. This will allow the vertex to be inserted at the beginning of the array instead of the end.
            We will also want to update the vertex to be the previous vertex so it can get added in. Set vertex to the vertex’s data in previous.

            6.All that’s left is to print out our results of calling shortestPathBetween() on vertices A and G. Add in a statement to print out results. We should see the distance is -38 and the path is A, D, E, and G.

            // dijkstras.js     - the same
            // testGraph.js     - the same

            // shortestPath.js
            const testGraph = require('./testGraph.js');
            const dijkstras = require('./dijkstras.js');

            const shortestPathBetween = (graph, startingVertex, targetVertex) => {
                const { distances, previous } = dijkstras(graph, startingVertex);
                
                const distance = distances[targetVertex.data];
                const path = [];

                let vertex = targetVertex;
                while(vertex) {
                    path.unshift(vertex);
                    vertex = previous[vertex.data];
                }

                return { distance, path };
            };

            // Retrieve shortest path between vertices A and G
            const a = testGraph.getVertexByValue('A');
            const g = testGraph.getVertexByValue('G');
            const results = shortestPathBetween(testGraph, a, g);
            console.log(results);

            module.exports = shortestPathBetween;

        Review
            We made it! Now that we have completed implmenting Dijkstra’s algorithm, let’s recap all the steps that we took.
            We first need to initialize the two objects that we would use to keep track of the shortest paths from the starting vertex to every vertex in the graph. The previous object keeps track of the preceding vertices in the path, like a reverse linked-list. We can use it to reconstruct the entire path, but backwards. The distances object keeps track of how far each vertex is from the starting vertex.
            Before we can start traversing through the edges in the graph, we must initialize each vertex’s distance and previous vertex. This is because up until now, we have not traversed down any paths to any of the vertices, so the initial distances should all be Infinity (and any actual paths are guaranteed to be less than the initial distance), and the previous vertices are all null. The only exception is the starting vertex where the distance from the starting vertex to itself is 0.

            distances = {}
            previous = {}

            for every vertex in the graph:
            distances[vertex] = Infinity
            previous[vertex] = null

            distances[starting vertex] = 0
            Next, a priority queue is used to traverse through the graph. In order for a vertex to be queued, the path to that vertex must be smaller than what was previously recorded in distances. We can initially queue up the starting vertex because no other paths have been evaluated yet, so the “path” to itself is the shortest so far.

            We continue to evaluate paths as long as there are vertices left in the queue. In order to evaluate new paths, we must dequeue a vertex from the queue and iterate through its neighbors. We then look at the distances to this vertex’s neighbors and the distance from the starting vertex to this vertex. The summation of these two distances is the full distance of the alternate path to the neighbor.

            distances = {}
            previous = {}
            queue = priority queue

            add starting vertex to queue

            for every vertex in the graph:
            distances[vertex] = Infinity
            previous[vertex] = null

            distances[starting vertex] = 0

            while there are vertices in the queue:
            dequeue vertex from queue

            for every neighbor in vertex:
                alternate = distances[vertex] + distance from vertex to neighbor
            Finally, we must compare the distance of the alternate path to the distance of the current path to the vertex. If the alternate path turns out to be shorter, then we want to ditch the current path and replace it with the alternate path. This means we will have to replace the neighbor’s previous vertex to the vertex, and the neighbor’s distance with the alternate distance.

            With the discovery of a shorter path to the neighbor, it raises the possibility of shorter paths to other vertices in the graph through this path. To cover this case, we should add the neighbor to the queue so we can explore its connected vertices.

            distances = {}
            previous = {}
            queue = priority queue

            add starting vertex to queue

            for every vertex in the graph:
            distances[vertex] = Infinity
            previous[vertex] = null

            distances[starting vertex] = 0

            while there are vertices in the queue:
            dequeue vertex from queue

            for every neighbor in vertex:
                alternate = distances[vertex] + distance from vertex to neighbor

                if alternate < distances[neighbor]:
                    distances[neighbor] = alternate
                    previous[neighbor] = vertex
                    add neighbor to queue


8. JavaScript Interview Prep and Algorithm Practice
    > Technical Interview Skills
    > JavaScript Algorithm Practice
        Sieve of Eratosthenes
        Capturing Rainwater
        Sorting with Custom Comparator Functions
        Introduction To Dynamic Programming in JavaScript
        The Knapsack Problem

-----------------------------------------------
Questions to ask in your software engineer interview
What has frustrated you about software engineers you have employed in the past?
What are the plans for the company over the next five to 10 years and how could I help you to achieve them? 
what's the first thing you would like me to concentrate on in this role? 